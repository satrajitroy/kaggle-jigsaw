{
 "cells": [
  {
   "cell_type": "code",
   "id": "6130d115",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-06T03:23:13.088864Z",
     "iopub.status.busy": "2025-08-06T03:23:13.088514Z",
     "iopub.status.idle": "2025-08-06T03:23:14.570472Z",
     "shell.execute_reply": "2025-08-06T03:23:14.569479Z"
    },
    "papermill": {
     "duration": 1.48678,
     "end_time": "2025-08-06T03:23:14.571891",
     "exception": false,
     "start_time": "2025-08-06T03:23:13.085111",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "for dirname, _, filenames in os.walk('.'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f871785f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T03:23:14.576980Z",
     "iopub.status.busy": "2025-08-06T03:23:14.576682Z",
     "iopub.status.idle": "2025-08-06T03:23:22.606345Z",
     "shell.execute_reply": "2025-08-06T03:23:22.605751Z"
    },
    "papermill": {
     "duration": 8.033448,
     "end_time": "2025-08-06T03:23:22.607731",
     "exception": false,
     "start_time": "2025-08-06T03:23:14.574283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch_directml\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c0225caa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T03:23:22.615788Z",
     "iopub.status.busy": "2025-08-06T03:23:22.615376Z",
     "iopub.status.idle": "2025-08-06T03:23:22.785666Z",
     "shell.execute_reply": "2025-08-06T03:23:22.784741Z"
    },
    "papermill": {
     "duration": 0.174062,
     "end_time": "2025-08-06T03:23:22.786979",
     "exception": false,
     "start_time": "2025-08-06T03:23:22.612917",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# -----------------------------\n",
    "# Load and preprocess data\n",
    "# -----------------------------\n",
    "# Use Kaggle paths when running on Kaggle\n",
    "# MODEL_PATH = \"/kaggle/input/xlm-roberta-base-offline/xlm_roberta_base_offline\"\n",
    "MODEL_PATH = \"C:/Users/satra/Downloads/xlm_roberta_base_offline\"\n",
    "\n",
    "# trn = \"/kaggle/input/jigsaw-agile-community-rules/train.csv\"\n",
    "# tst = \"/kaggle/input/jigsaw-agile-community-rules/test.csv\"\n",
    "# trn = \"C:/Users/satra/PycharmProjects/kaggle-jigsaw/train.csv\"\n",
    "# tst = \"C:/Users/satra/PycharmProjects/kaggle-jigsaw/test.csv\"\n",
    "# df_trn = pd.read_csv(trn)\n",
    "# df_trn = df_trn.sample(frac=.01, random_state=42).reset_index(drop=True)\n",
    "# df_tst = pd.read_csv(tst)\n",
    "\n",
    "\n",
    "def getText(value):\n",
    "    return str(value) if pd.notna(value) else ''\n",
    "\n",
    "\n",
    "def fill_empty_examples_pandas(df):\n",
    "    \"\"\"Fills NaN in example columns with empty strings and then propagates non-empty examples.\"\"\"\n",
    "    example_cols = ['positive_example_1', 'positive_example_2', 'negative_example_1', 'negative_example_2']\n",
    "\n",
    "    # Ensure all example columns are strings and NaNs are empty strings\n",
    "    for col in example_cols:\n",
    "        df[col] = df[col].fillna('').astype(str)\n",
    "\n",
    "    # Propagate non-empty examples to empty slots\n",
    "    df['positive_example_1'] = df['positive_example_1'].mask(df['positive_example_1'] == '', df[\n",
    "'positive_example_2'])\n",
    "    df['positive_example_2'] = df['positive_example_2'].mask(df['positive_example_2'] == '', df[\n",
    "'positive_example_1'])\n",
    "    df['negative_example_1'] = df['negative_example_1'].mask(df['negative_example_1'] == '', df[\n",
    "'negative_example_2'])\n",
    "    df['negative_example_2'] = df['negative_example_2'].mask(df['negative_example_2'] == '', df[\n",
    "'negative_example_1'])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_multi_input_row(row, text_to_classify_field_name):\n",
    "    \"\"\"\n",
    "    Creates the dictionary of 7 text inputs for a single row.\n",
    "    'text_to_classify_field_name' specifies which column (e.g., 'body', 'positive_example_1')\n",
    "    should be used for the 'text_to_classify' input.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"text_to_classify\": getText(row[text_to_classify_field_name]), # This is the dynamic part\n",
    "        \"rule\": getText(row[\"rule\"]),\n",
    "        \"subreddit\": getText(row[\"subreddit\"]),\n",
    "        \"pos1\": getText(row['positive_example_1']),\n",
    "        \"pos2\": getText(row['positive_example_2']),\n",
    "        \"neg1\": getText(row['negative_example_1']),\n",
    "        \"neg2\": getText(row['negative_example_2']),\n",
    "    }\n",
    "\n",
    "\n",
    "# trn_path = \"/kaggle/input/jigsaw-agile-community-rules/train.csv\"\n",
    "# tst_path = \"/kaggle/input/jigsaw-agile-community-rules/test.csv\"\n",
    "trn_path = \"C:/Users/satra/PycharmProjects/kaggle-jigsaw/train.csv\"\n",
    "tst_path = \"C:/Users/satra/PycharmProjects/kaggle-jigsaw/test.csv\"\n",
    "df_trn_orig = pd.read_csv(trn_path) # Keep original df_trn for KFold split\n",
    "df_tst_orig = pd.read_csv(tst_path)\n",
    "\n",
    "# Apply example filling to original dataframes (before creating 'inputs' column)\n",
    "df_trn_orig = fill_empty_examples_pandas(df_trn_orig)\n",
    "df_tst_orig = fill_empty_examples_pandas(df_tst_orig)\n",
    "\n",
    "df_trn_orig[\"inputs\"] = df_trn_orig.apply(lambda row: create_multi_input_row(row, \"body\"), axis=1)\n",
    "df_tst_orig[\"inputs\"] = df_tst_orig.apply(lambda row: create_multi_input_row(row, \"body\"), axis=1)\n",
    "\n",
    "print(f\"Original df_trn_orig shape: {df_trn_orig.shape}\")\n",
    "print(f\"Original df_tst_orig shape: {df_tst_orig.shape}\")\n",
    "\n",
    "\n",
    "text_feature_cols = [\n",
    "    'body',\n",
    "    'rule',\n",
    "    'subreddit',\n",
    "    'positive_example_1',\n",
    "    'positive_example_2',\n",
    "    'negative_example_1',\n",
    "    'negative_example_2'\n",
    "]\n",
    "\n",
    "print(\"--- Comprehensive NaN Inspection for All Text Feature Columns ---\")\n",
    "\n",
    "# Count NaNs for each text feature column\n",
    "print(\"\\n--- NaN Counts per Text Feature Column ---\")\n",
    "print(df_trn_orig[text_feature_cols].isnull().sum())\n",
    "\n",
    "# Analyze rows with NaNs in 'body' (most critical)\n",
    "print(\"\\n--- Analysis for 'body' column NaNs ---\")\n",
    "body_nan_rows = df_trn_orig[df_trn_orig['body'].isnull()]\n",
    "if not body_nan_rows.empty:\n",
    "    print(f\"Number of rows with NaN in 'body': {len(body_nan_rows)}\")\n",
    "    print(\"Rule violation distribution for rows with NaN in 'body':\")\n",
    "    print(body_nan_rows['rule_violation'].value_counts(normalize=True))\n",
    "else:\n",
    "    print(\"No NaN values found in 'body' column.\")\n",
    "\n",
    "# Analyze rows with NaNs in 'rule'\n",
    "print(\"\\n--- Analysis for 'rule' column NaNs ---\")\n",
    "rule_nan_rows = df_trn_orig[df_trn_orig['rule'].isnull()]\n",
    "if not rule_nan_rows.empty:\n",
    "    print(f\"Number of rows with NaN in 'rule': {len(rule_nan_rows)}\")\n",
    "    print(\"Rule violation distribution for rows with NaN in 'rule':\")\n",
    "    print(rule_nan_rows['rule_violation'].value_counts(normalize=True))\n",
    "else:\n",
    "    print(\"No NaN values found in 'rule' column.\")\n",
    "\n",
    "# Analyze rows with NaNs in 'subreddit'\n",
    "print(\"\\n--- Analysis for 'subreddit' column NaNs ---\")\n",
    "subreddit_nan_rows = df_trn_orig[df_trn_orig['subreddit'].isnull()]\n",
    "if not subreddit_nan_rows.empty:\n",
    "    print(f\"Number of rows with NaN in 'subreddit': {len(subreddit_nan_rows)}\")\n",
    "    print(\"Rule violation distribution for rows with NaN in 'subreddit':\")\n",
    "    print(subreddit_nan_rows['rule_violation'].value_counts(normalize=True))\n",
    "else:\n",
    "    print(\"No NaN values found in 'subreddit' column.\")\n",
    "\n",
    "# Analyze rows where ANY of the example columns are NaN\n",
    "print(\"\\n--- Analysis for Example Columns NaNs ---\")\n",
    "example_only_cols = [col for col in text_feature_cols if 'example' in col]\n",
    "df_any_example_nan = df_trn_orig[df_trn_orig[example_only_cols].isnull().any(axis=1)]\n",
    "if not df_any_example_nan.empty:\n",
    "    print(f\"Number of rows with NaN in ANY example column: {len(df_any_example_nan)}\")\n",
    "    print(\"Rule violation distribution for rows with NaN in ANY example column:\")\n",
    "    print(df_any_example_nan['rule_violation'].value_counts(normalize=True))\n",
    "else:\n",
    "    print(\"No NaN values found in any example column.\")\n",
    "\n",
    "# Overall rule_violation distribution (for comparison)\n",
    "print(f\"\\n--- Overall rule_violation distribution: ---\")\n",
    "print(df_trn_orig['rule_violation'].value_counts(normalize=True))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a337b9c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T03:23:22.792672Z",
     "iopub.status.busy": "2025-08-06T03:23:22.792125Z",
     "iopub.status.idle": "2025-08-06T03:23:22.801183Z",
     "shell.execute_reply": "2025-08-06T03:23:22.800519Z"
    },
    "papermill": {
     "duration": 0.013059,
     "end_time": "2025-08-06T03:23:22.802366",
     "exception": false,
     "start_time": "2025-08-06T03:23:22.789307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "MAX_LEN = 128\n",
    "N_EPOCHS = 8\n",
    "k_folds = 5\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset\n",
    "# -----------------------------\n",
    "class MultiInputDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len=MAX_LEN, is_test=False):\n",
    "        self.dataframe = dataframe # This dataframe already has the 'inputs' column\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        item = {}\n",
    "        # Loop over the 7 fields that are keys in text_inputs_dict\n",
    "        for field in [\"text_to_classify\", \"rule\", \"subreddit\", \"pos1\", \"pos2\", \"neg1\", \"neg2\"]:\n",
    "            encoded = self.tokenizer(\n",
    "                row[field], # Access from the dictionary\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                max_length=MAX_LEN,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            for key in encoded:\n",
    "                item[f\"{field}_{key}\"] = encoded[key].squeeze(0)\n",
    "\n",
    "        if not self.is_test:\n",
    "            item[\"label\"] = torch.tensor(row[\"rule_violation\"], dtype=torch.float32)\n",
    "        return item\n",
    "\n",
    "# -----------------------------\n",
    "# Model\n",
    "# -----------------------------\n",
    "class MultiInputBERT(nn.Module):\n",
    "    def __init__(self, model_name='xlm-roberta-base'):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(768 * 7, 256), # 7 inputs * 768 hidden size\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1) # Output a single logit\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        cls_outputs = []\n",
    "        # Loop over the 7 fields that are keys in the 'inputs' dictionary\n",
    "        for field in [\"text_to_classify\", \"rule\", \"subreddit\", \"pos1\", \"pos2\", \"neg1\", \"neg2\"]:\n",
    "            out = self.bert(\n",
    "                input_ids=inputs[f\"{field}_input_ids\"],\n",
    "                attention_mask=inputs[f\"{field}_attention_mask\"]\n",
    "            )\n",
    "            cls_outputs.append(out.last_hidden_state[:, 0])  # CLS token\n",
    "        x = torch.cat(cls_outputs, dim=1)\n",
    "        x = self.dropout(x)\n",
    "        return self.classifier(x)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7164fed554d946d7",
   "metadata": {},
   "source": [
    "# -----------------------------\n",
    "# Training and Evaluation\n",
    "# -----------------------------\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    # Try to detect NVIDIA CUDA GPU first\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f\"Using NVIDIA CUDA GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.2f} GB\")\n",
    "        return device\n",
    "\n",
    "    # If no NVIDIA CUDA GPU, try to detect DirectML GPU\n",
    "    try:\n",
    "        if torch_directml.is_available():\n",
    "            device = torch_directml.device()\n",
    "            print(f\"Using DirectML GPU: {device}\")\n",
    "            # Add a small test to ensure it's truly usable\n",
    "            try:\n",
    "                _ = torch.tensor([1], device=device)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: DirectML device found but not usable ({e}). Falling back to CPU.\")\n",
    "                return torch.device(\"cpu\")\n",
    "            return device\n",
    "        else:\n",
    "            print(\"DirectML is NOT available.\")\n",
    "    except ImportError:\n",
    "        print(\"torch_directml not installed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking DirectML: {e}. Falling back to CPU.\")\n",
    "\n",
    "    # If neither GPU is found, fall back to CPU\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU (NVIDIA CUDA or DirectML) found. Using CPU.\")\n",
    "    return device\n",
    "\n",
    "\n",
    "device = get_device()\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# print(\"\\n--- Debugging df_tst Preparation ---\")\n",
    "# print(f\"df_tst shape after fill_empty_examples_pandas: {df_tst_orig.shape}\")\n",
    "# print(f\"df_tst 'inputs' head:\\n{df_tst_orig['inputs'].head()}\")\n",
    "# # Check if any 'text_to_classify' is empty in test set\n",
    "# df_tst_temp_dataset = MultiInputDataset(df_tst_orig, tokenizer, is_test=True)\n",
    "# sample_item = df_tst_temp_dataset[0] # Get first item\n",
    "# print(f\"Sample test item keys: {sample_item.keys()}\")\n",
    "# print(f\"Sample test item 'text_to_classify_input_ids' shape: {sample_item['text_to_classify_input_ids'].shape}\")\n",
    "# print(f\"Sample test item 'rule_input_ids' shape: {sample_item['rule_input_ids'].shape}\")\n",
    "# print(f\"Sample test item 'subreddit_input_ids' shape: {sample_item['subreddit_input_ids'].shape}\")\n",
    "# # Check if any of the input_ids are all zeros (indicating empty text)\n",
    "# print(f\"Test body input_ids sum (first item): {sample_item['text_to_classify_input_ids'].sum()}\")\n",
    "# print(f\"Test rule input_ids sum (first item): {sample_item['rule_input_ids'].sum()}\")\n",
    "# print(f\"Test subreddit input_ids sum (first item): {sample_item['subreddit_input_ids'].sum()}\")"
   ],
   "id": "8c7b51abe1a1d6e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T19:49:49.843426Z",
     "start_time": "2025-08-06T19:49:49.143307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "oof_preds = np.zeros(len(df_trn_orig))\n",
    "test_preds_folds = [] # This is correct\n",
    "\n",
    "for fold, (train_idx_orig, val_idx_orig) in enumerate(skf.split(df_trn_orig, df_trn_orig[\"rule_violation\"])):\n",
    "    print(f\"\\n----- Fold {fold+1} -----\")\n",
    "    # train_df = df_trn.iloc[train_idx].reset_index(drop=True)\n",
    "    # 1. Create original train and validation DataFrames for this fold\n",
    "    fold_train_df_orig = df_trn_orig.iloc[train_idx_orig].reset_index(drop=True)\n",
    "    fold_val_df_orig = df_trn_orig.iloc[val_idx_orig].reset_index(drop=True)\n",
    "\n",
    "    # 2. EXPAND the TRAINING data for this fold (ONLY from fold_train_df_orig)\n",
    "    # This is the df_expanded_train for THIS fold\n",
    "    expanded_train_data_list = []\n",
    "    for idx, row in fold_train_df_orig.iterrows():\n",
    "        # Add original body as a training sample\n",
    "        expanded_train_data_list.append(create_multi_input_row(row, \"body\"))\n",
    "        # Add positive examples\n",
    "        expanded_train_data_list.append(create_multi_input_row(row, \"positive_example_1\"))\n",
    "        expanded_train_data_list.append(create_multi_input_row(row, \"positive_example_2\"))\n",
    "        # Add negative examples\n",
    "        expanded_train_data_list.append(create_multi_input_row(row, \"negative_example_1\"))\n",
    "        expanded_train_data_list.append(create_multi_input_row(row, \"negative_example_2\"))\n",
    "\n",
    "    fold_train_df_expanded = pd.DataFrame(expanded_train_data_list)\n",
    "\n",
    "    # Filter out rows where 'text_to_classify' might be empty after getText (from original NaNs)\n",
    "    fold_train_df_expanded = fold_train_df_expanded[fold_train_df_expanded['text_to_classify'] != ''].reset_index(drop=True)\n",
    "\n",
    "    # 3. Prepare the VALIDATION data for this fold (using original body from fold_val_df_orig)\n",
    "    # This DataFrame will have an 'inputs' column with the 7 fields, where 'text_to_classify' is 'body'\n",
    "    fold_val_df_for_model = fold_val_df_orig.copy()\n",
    "    fold_val_df_for_model['text_to_classify'] = fold_val_df_for_model['body']\n",
    "    # Ensure all 7 fields are present as columns\n",
    "    fold_val_df_for_model['pos1'] = fold_val_df_for_model['positive_example_1'].apply(getText)\n",
    "    fold_val_df_for_model['pos2'] = fold_val_df_for_model['positive_example_2'].apply(getText)\n",
    "    fold_val_df_for_model['neg1'] = fold_val_df_for_model['negative_example_1'].apply(getText)\n",
    "    fold_val_df_for_model['neg2'] = fold_val_df_for_model['negative_example_2'].apply(getText)\n",
    "    fold_val_df_for_model['rule_violation'] = fold_val_df_orig['rule_violation'].values\n",
    "    # Apply the fill logic for examples to fold_val_df_for_model as well\n",
    "    fold_val_df_for_model = fill_empty_examples_pandas(fold_val_df_for_model)\n",
    "\n",
    "    # 4. Create Datasets and DataLoaders\n",
    "    train_dataset = MultiInputDataset(fold_train_df_expanded, tokenizer, 1e-6) # Train on expanded data\n",
    "    val_dataset = MultiInputDataset(fold_val_df_for_model, tokenizer, 512) # Validate on original body\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "    # Test loader is created once per fold, using df_tst_orig\n",
    "    df_tst_for_model = df_tst_orig.copy()\n",
    "    df_tst_for_model['text_to_classify'] = df_tst_for_model['body']\n",
    "    # Ensure all 7 fields are present as columns\n",
    "    df_tst_for_model['pos1'] = df_tst_for_model['positive_example_1'].apply(getText)\n",
    "    df_tst_for_model['pos2'] = df_tst_for_model['positive_example_2'].apply(getText)\n",
    "    df_tst_for_model['neg1'] = df_tst_for_model['negative_example_1'].apply(getText)\n",
    "    df_tst_for_model['neg2'] = df_tst_for_model['negative_example_2'].apply(getText)\n",
    "    # Apply the fill logic for examples to df_tst_for_model as well\n",
    "    df_tst_for_model = fill_empty_examples_pandas(df_tst_for_model)\n",
    "\n",
    "    test_loader = DataLoader(MultiInputDataset(df_tst_for_model, tokenizer, is_test=True), batch_size=8, shuffle=False)\n",
    "\n",
    "    model = MultiInputBERT(model_name=MODEL_PATH).to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-6)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    num_training_steps_per_fold = len(train_loader) * N_EPOCHS\n",
    "    num_warmup_steps_per_fold = int(num_training_steps_per_fold * 0.05) # 5% warmup\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=num_warmup_steps_per_fold,\n",
    "        num_training_steps=num_training_steps_per_fold\n",
    "    )\n",
    "\n",
    "    # Training Loop for this fold\n",
    "    best_auc = -1.0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch + 1}\"):\n",
    "            inputs = {k: v.to(device) for k, v in batch.items() if k != \"label\"}\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            logits = outputs.squeeze(-1)\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # Gradient clipping\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1} Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "        # Eval\n",
    "        model.eval()\n",
    "        all_val_preds_raw, all_val_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=f\"Validating Epoch {epoch + 1}\"):\n",
    "                inputs = {k: v.to(device) for k, v in batch.items() if k != \"label\"}\n",
    "                labels = batch[\"label\"].to(device)\n",
    "                outputs = model(inputs)\n",
    "                logits = outputs.squeeze(-1)\n",
    "\n",
    "                probs = torch.sigmoid(logits).detach().cpu().tolist()\n",
    "                all_val_preds_raw.extend(probs)\n",
    "                all_val_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "            preds = [int(p > 0.5) for p in all_val_preds_raw]\n",
    "            print(classification_report(all_val_labels, preds, digits=3, zero_division=0))\n",
    "            curr_auc = roc_auc_score(all_val_labels, all_val_preds_raw)\n",
    "            print(f\"AUC Score: {curr_auc:.4f}\")\n",
    "\n",
    "            if curr_auc > best_auc:\n",
    "                best_auc = curr_auc\n",
    "                best_model_state = model.state_dict()\n",
    "                print(f\"  -> New best Val AUC for Fold {fold + 1}: {best_auc:.4f}\")\n",
    "\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(f\"Fold {fold + 1} Best Val AUC: {best_auc:.4f}\")\n",
    "\n",
    "    # Make OOF predictions for this fold's validation set\n",
    "    model.eval()\n",
    "    fold_val_preds_list = []\n",
    "    fold_val_true_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f\"Fold {fold + 1} OOF Prediction\"):\n",
    "            inputs = {k: v.to(device) for k, v in batch.items() if k != \"label\"}\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            outputs = model(inputs)\n",
    "            logits = outputs.squeeze(-1)\n",
    "            probs = torch.sigmoid(logits).detach().cpu().tolist()\n",
    "            fold_val_preds_list.extend(probs)\n",
    "            fold_val_true_list.extend(labels.cpu().tolist())\n",
    "\n",
    "    oof_fold_auc_check = roc_auc_score(fold_val_true_list, fold_val_preds_list)\n",
    "    print(f\"Fold {fold + 1} OOF AUC Check: {oof_fold_auc_check:.4f} (Must match Best Val AUC)\")\n",
    "\n",
    "    oof_preds[val_idx_orig] = np.array(fold_val_preds_list) # Use val_idx_orig from kf.split\n",
    "\n",
    "    # Make predictions on the TEST set using this fold's best model\n",
    "    test_fold_preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=f\"Fold {fold + 1} Test Prediction\"):\n",
    "            inputs = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(inputs)\n",
    "            logits = outputs.squeeze(-1)\n",
    "            probs = torch.sigmoid(logits).detach().cpu().tolist()\n",
    "            test_fold_preds.extend(probs)\n",
    "\n",
    "    test_preds_folds.append(test_fold_preds)"
   ],
   "id": "114a124d81b3140e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Fold 1 -----\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (1623) does not match length of index (8115)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 25\u001B[39m\n\u001B[32m     22\u001B[39m     expanded_train_data_list.append(create_multi_input_row(row, \u001B[33m\"\u001B[39m\u001B[33mnegative_example_2\u001B[39m\u001B[33m\"\u001B[39m))\n\u001B[32m     24\u001B[39m fold_train_df_expanded = pd.DataFrame(expanded_train_data_list)\n\u001B[32m---> \u001B[39m\u001B[32m25\u001B[39m \u001B[43mfold_train_df_expanded\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mrule_violation\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m = fold_train_df_orig[\u001B[33m'\u001B[39m\u001B[33mrule_violation\u001B[39m\u001B[33m'\u001B[39m].values\n\u001B[32m     27\u001B[39m \u001B[38;5;66;03m# Filter out rows where 'text_to_classify' might be empty after getText (from original NaNs)\u001B[39;00m\n\u001B[32m     28\u001B[39m fold_train_df_expanded = fold_train_df_expanded[fold_train_df_expanded[\u001B[33m'\u001B[39m\u001B[33mtext_to_classify\u001B[39m\u001B[33m'\u001B[39m] != \u001B[33m'\u001B[39m\u001B[33m'\u001B[39m].reset_index(drop=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\frame.py:4316\u001B[39m, in \u001B[36mDataFrame.__setitem__\u001B[39m\u001B[34m(self, key, value)\u001B[39m\n\u001B[32m   4313\u001B[39m     \u001B[38;5;28mself\u001B[39m._setitem_array([key], value)\n\u001B[32m   4314\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   4315\u001B[39m     \u001B[38;5;66;03m# set column\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m4316\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_set_item\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\frame.py:4529\u001B[39m, in \u001B[36mDataFrame._set_item\u001B[39m\u001B[34m(self, key, value)\u001B[39m\n\u001B[32m   4519\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_set_item\u001B[39m(\u001B[38;5;28mself\u001B[39m, key, value) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   4520\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   4521\u001B[39m \u001B[33;03m    Add series to DataFrame in specified column.\u001B[39;00m\n\u001B[32m   4522\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m   4527\u001B[39m \u001B[33;03m    ensure homogeneity.\u001B[39;00m\n\u001B[32m   4528\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m4529\u001B[39m     value, refs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_sanitize_column\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4531\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m   4532\u001B[39m         key \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.columns\n\u001B[32m   4533\u001B[39m         \u001B[38;5;129;01mand\u001B[39;00m value.ndim == \u001B[32m1\u001B[39m\n\u001B[32m   4534\u001B[39m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value.dtype, ExtensionDtype)\n\u001B[32m   4535\u001B[39m     ):\n\u001B[32m   4536\u001B[39m         \u001B[38;5;66;03m# broadcast across multiple columns if necessary\u001B[39;00m\n\u001B[32m   4537\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m.columns.is_unique \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m.columns, MultiIndex):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\frame.py:5273\u001B[39m, in \u001B[36mDataFrame._sanitize_column\u001B[39m\u001B[34m(self, value)\u001B[39m\n\u001B[32m   5270\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m _reindex_for_setitem(value, \u001B[38;5;28mself\u001B[39m.index)\n\u001B[32m   5272\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_list_like(value):\n\u001B[32m-> \u001B[39m\u001B[32m5273\u001B[39m     \u001B[43mcom\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrequire_length_match\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   5274\u001B[39m arr = sanitize_array(value, \u001B[38;5;28mself\u001B[39m.index, copy=\u001B[38;5;28;01mTrue\u001B[39;00m, allow_2d=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m   5275\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m   5276\u001B[39m     \u001B[38;5;28misinstance\u001B[39m(value, Index)\n\u001B[32m   5277\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m value.dtype == \u001B[33m\"\u001B[39m\u001B[33mobject\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   (...)\u001B[39m\u001B[32m   5280\u001B[39m     \u001B[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001B[39;00m\n\u001B[32m   5281\u001B[39m     \u001B[38;5;66;03m# this deprecation\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\common.py:573\u001B[39m, in \u001B[36mrequire_length_match\u001B[39m\u001B[34m(data, index)\u001B[39m\n\u001B[32m    569\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    570\u001B[39m \u001B[33;03mCheck the length of data matches the length of the index.\u001B[39;00m\n\u001B[32m    571\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    572\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(data) != \u001B[38;5;28mlen\u001B[39m(index):\n\u001B[32m--> \u001B[39m\u001B[32m573\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    574\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mLength of values \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    575\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(data)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m) \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    576\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mdoes not match length of index \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    577\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(index)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m)\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    578\u001B[39m     )\n",
      "\u001B[31mValueError\u001B[39m: Length of values (1623) does not match length of index (8115)"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------\n",
    "# Final Calculation and Submission\n",
    "# -----------------------------\n",
    "overall_oof_auc = roc_auc_score(df_trn_orig['rule_violation'], oof_preds)\n",
    "print(f\"\\n--- Overall {k_folds}-Fold OOF AUC: {overall_oof_auc:.4f} ---\")\n",
    "\n",
    "# Average test predictions across all folds\n",
    "final_test_predictions = np.mean(test_preds_folds, axis=0)\n",
    "\n",
    "print(\"\\n--- Final Test Predictions Statistics ---\")\n",
    "print(f\"Min: {np.min(final_test_predictions):.4f}\")\n",
    "print(f\"Max: {np.max(final_test_predictions):.4f}\")\n",
    "print(f\"Mean: {np.mean(final_test_predictions):.4f}\")\n",
    "print(f\"Std Dev: {np.std(final_test_predictions):.4f}\")\n",
    "# Check distribution\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist(final_test_predictions, bins=50)\n",
    "plt.title(\"Distribution of Final Test Predictions\")\n",
    "plt.xlabel(\"Predicted Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# Create final submission file\n",
    "submission = pd.DataFrame({\n",
    "    \"row_id\": df_tst_orig[\"row_id\"],\n",
    "    \"rule_violation\": final_test_predictions\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False) # Save with a distinct name\n",
    "print(\"K-Fold multi-input submission.csv created successfully!\")\n",
    "print(submission.head(10))"
   ],
   "id": "af8be6a5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 13121456,
     "isSourceIdPinned": false,
     "sourceId": 94635,
     "sourceType": "competition"
    },
    {
     "datasetId": 7984956,
     "sourceId": 12636496,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15818.859754,
   "end_time": "2025-08-06T07:46:47.714661",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-06T03:23:08.854907",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
