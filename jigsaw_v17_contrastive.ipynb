{
 "cells": [
  {
   "cell_type": "code",
   "id": "6130d115",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-06T03:23:13.088864Z",
     "iopub.status.busy": "2025-08-06T03:23:13.088514Z",
     "iopub.status.idle": "2025-08-06T03:23:14.570472Z",
     "shell.execute_reply": "2025-08-06T03:23:14.569479Z"
    },
    "papermill": {
     "duration": 1.48678,
     "end_time": "2025-08-06T03:23:14.571891",
     "exception": false,
     "start_time": "2025-08-06T03:23:13.085111",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-08-07T13:36:56.687474Z",
     "start_time": "2025-08-07T13:36:56.264195Z"
    }
   },
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "for dirname, _, filenames in os.walk('.'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\Jigsaw.ipynb\n",
      ".\\Jigsaw.py\n",
      ".\\Jigsaw_v14.py\n",
      ".\\jigsaw_v15.ipynb\n",
      ".\\jigsaw_v17.ipynb\n",
      ".\\jigsaw_v17_contrastive.ipynb\n",
      ".\\output.log\n",
      ".\\README.md\n",
      ".\\sample_submission.csv\n",
      ".\\StackTrace\n",
      ".\\submission.csv\n",
      ".\\test.csv\n",
      ".\\train.csv\n",
      ".\\.git\\COMMIT_EDITMSG\n",
      ".\\.git\\config\n",
      ".\\.git\\description\n",
      ".\\.git\\FETCH_HEAD\n",
      ".\\.git\\HEAD\n",
      ".\\.git\\index\n",
      ".\\.git\\ORIG_HEAD\n",
      ".\\.git\\packed-refs\n",
      ".\\.git\\hooks\\applypatch-msg.sample\n",
      ".\\.git\\hooks\\commit-msg.sample\n",
      ".\\.git\\hooks\\fsmonitor-watchman.sample\n",
      ".\\.git\\hooks\\post-update.sample\n",
      ".\\.git\\hooks\\pre-applypatch.sample\n",
      ".\\.git\\hooks\\pre-commit.sample\n",
      ".\\.git\\hooks\\pre-merge-commit.sample\n",
      ".\\.git\\hooks\\pre-push.sample\n",
      ".\\.git\\hooks\\pre-rebase.sample\n",
      ".\\.git\\hooks\\pre-receive.sample\n",
      ".\\.git\\hooks\\prepare-commit-msg.sample\n",
      ".\\.git\\hooks\\push-to-checkout.sample\n",
      ".\\.git\\hooks\\sendemail-validate.sample\n",
      ".\\.git\\hooks\\update.sample\n",
      ".\\.git\\info\\exclude\n",
      ".\\.git\\logs\\HEAD\n",
      ".\\.git\\logs\\refs\\heads\\main\n",
      ".\\.git\\logs\\refs\\remotes\\origin\\HEAD\n",
      ".\\.git\\logs\\refs\\remotes\\origin\\main\n",
      ".\\.git\\objects\\01\\d3562f054ec88ad3f570933b85e6346d2925e6\n",
      ".\\.git\\objects\\06\\572006ed0de266d90dd5909fe65586a4dcb3e8\n",
      ".\\.git\\objects\\06\\6cb8a786a0ff08f989d27d029142f6ef538726\n",
      ".\\.git\\objects\\0b\\106c69ed4e685dfa3bf61075273efa61c9e492\n",
      ".\\.git\\objects\\0d\\80b9e47dddde1c902e3926c177864697811de2\n",
      ".\\.git\\objects\\13\\81744334112bee79c0aaec5104c165c863c99e\n",
      ".\\.git\\objects\\14\\92b73c5b3b48f77cc96731104e197361e44028\n",
      ".\\.git\\objects\\15\\c077795b435663f9d0379e0613ec669f425cf7\n",
      ".\\.git\\objects\\17\\93a42288d7010af98aec0fa2ddef03fe1c3686\n",
      ".\\.git\\objects\\21\\b7494f37ca92f8ac02f32b2c0eeae0ac1e5288\n",
      ".\\.git\\objects\\23\\0d03df73118b191cdd29f3cd51d141c546cc53\n",
      ".\\.git\\objects\\23\\be0b99347607f8a9d1b073ee2a8b86c00c6262\n",
      ".\\.git\\objects\\29\\216318041a468acafbba2ae1e1912e510a4f07\n",
      ".\\.git\\objects\\2c\\b0fa1244b31607ac7db2d8ffe52dccd2e35ee8\n",
      ".\\.git\\objects\\2d\\ad6c44abd971bfc89d7c17efac22ba464dbd94\n",
      ".\\.git\\objects\\2f\\a5dab28205ab237a070749882b248709ca0544\n",
      ".\\.git\\objects\\30\\104ae4dcf36ec88789f3317d5a4ad6366db585\n",
      ".\\.git\\objects\\36\\bc2b649aeb693222dc7c961c79e3f2fbb3ec1e\n",
      ".\\.git\\objects\\39\\a1e8e55eed860ac073e85e736c730144ce1d13\n",
      ".\\.git\\objects\\42\\11cdce7f5ae8293b325e97870e0058d3df40ec\n",
      ".\\.git\\objects\\45\\ebf96e63da28cf649c32aad3fb998484ec556c\n",
      ".\\.git\\objects\\47\\9416cc2e8514a806ac5f137de2bc849012bb14\n",
      ".\\.git\\objects\\4d\\4250314c1c9200b767a28bc55f64d2195c5ae2\n",
      ".\\.git\\objects\\4e\\de82e5f182372d31c0eadaed84c2fb95d7509a\n",
      ".\\.git\\objects\\53\\c5538e5dc70d8044d01356d88f57a13b63d089\n",
      ".\\.git\\objects\\54\\e79b817afb23553a2699665bc78c2324f5d9dd\n",
      ".\\.git\\objects\\58\\19b597cf902e426d3c3af29a2259b79bbba9ee\n",
      ".\\.git\\objects\\5c\\7c92cb4803ba7c542c9d235cc55e28215777e3\n",
      ".\\.git\\objects\\5c\\a77c7e3a6d83a3de446565f3fc85309ee73fb3\n",
      ".\\.git\\objects\\64\\ee493f7957516d0c4f0285a5c9fd2da6c7d31a\n",
      ".\\.git\\objects\\68\\b7a7585d59cbd1cffce197b1416a13e3f493d5\n",
      ".\\.git\\objects\\69\\b3db3c18e4fd700289f7043f2f2c9144ab5e70\n",
      ".\\.git\\objects\\6c\\4a060738e8286a7f390d1a457683032826495b\n",
      ".\\.git\\objects\\6c\\60922e960eaa6e3b2eb4750b9a179c5d0495c2\n",
      ".\\.git\\objects\\6d\\83a1afac3899931f713d2d32fd61ea7d7d0e9b\n",
      ".\\.git\\objects\\6e\\54912db9fec3b019604be8202deb0928fe536e\n",
      ".\\.git\\objects\\6e\\7c376e7d325be665c71c902399e9603821865b\n",
      ".\\.git\\objects\\6e\\bd8ae0aa7196a627f33700eb9bc351e38e9458\n",
      ".\\.git\\objects\\71\\47e5338b58be420f038df95c5472247a45773b\n",
      ".\\.git\\objects\\71\\a2b9f664684152e3a9407972d0172824b3923d\n",
      ".\\.git\\objects\\72\\eea560a9be796ea318f315cbf84a416bf80d93\n",
      ".\\.git\\objects\\77\\9f3be55164e7dfce8b63cfc4bc374183cf4ce2\n",
      ".\\.git\\objects\\7b\\1e942828db2d7889bc8bc36e8ed698eccce01f\n",
      ".\\.git\\objects\\7b\\cb87c23b67b74d7934da3a98141d33f2bce9fb\n",
      ".\\.git\\objects\\7c\\0e861373cafe10549130a29ceca5cb22412299\n",
      ".\\.git\\objects\\7e\\40a08d8df1c594acf181d5005ada8a1bf79bc7\n",
      ".\\.git\\objects\\83\\2c3ade2351131e4ba13499c735ce340225804c\n",
      ".\\.git\\objects\\8a\\778314dc06c93c70f11807a25cb2af3a4c7be1\n",
      ".\\.git\\objects\\8a\\caf73eedcb1cffcd709093702f0847c6065c0a\n",
      ".\\.git\\objects\\8e\\13343923b0b824b1a2c0367b31d27018d06370\n",
      ".\\.git\\objects\\8e\\4c93409be61d0f6150283fbe477203aac9b8b6\n",
      ".\\.git\\objects\\95\\2999091dc373da5ede3ba7fa46dabb8b95b1d4\n",
      ".\\.git\\objects\\95\\b71db0ae7eddb009504679522afa1f0d2a72ff\n",
      ".\\.git\\objects\\96\\89fab5fd7d5eeecccda960c83b9196de6f7c82\n",
      ".\\.git\\objects\\9b\\68efb98a65294f8cd693178d8ee0417633b491\n",
      ".\\.git\\objects\\9c\\5ce1255a16d86acb201d36706e7e7ee7928479\n",
      ".\\.git\\objects\\a1\\b769e1fd54059afd0f28dcab759f2dbc9bc7da\n",
      ".\\.git\\objects\\a5\\5b965b4813f502846f98a181a6501be8ee30a5\n",
      ".\\.git\\objects\\a7\\f4595cd48bb6ceb05c20552f996975286a2532\n",
      ".\\.git\\objects\\aa\\b6f01d92a6c8a9731a64c72b769006fcc15b7b\n",
      ".\\.git\\objects\\ae\\d198e6961af9f55f9a776bb2eb2fc47cb206c7\n",
      ".\\.git\\objects\\b6\\1a92e88fe2b63a4c1d29e055c21c806f687267\n",
      ".\\.git\\objects\\bb\\6b516c39873f00c8f3c2a05b19a222a505ce58\n",
      ".\\.git\\objects\\bc\\39b66e36e3768981bfab17bd73fe660f5578d2\n",
      ".\\.git\\objects\\bc\\db1d0a654e170f3b9a2c641071c9fb2314c6e0\n",
      ".\\.git\\objects\\cf\\56b85e07ab2cac0f4d09f9e9a0e2850d9a934e\n",
      ".\\.git\\objects\\d5\\01d1e57e0aba3377717496e4784d56466ea0ce\n",
      ".\\.git\\objects\\d9\\26de446ab74f7db66835553696eeac4dfe4f89\n",
      ".\\.git\\objects\\da\\5b45771597e5c92b756307bf28c56c7ceae825\n",
      ".\\.git\\objects\\e2\\6853bb0afa31685f4aa3a8d132853e68a2967f\n",
      ".\\.git\\objects\\f8\\3a54792e6472a0efc4b894c27db1f7a7c0c470\n",
      ".\\.git\\objects\\fb\\482effcb040ef5131e766b261dafec21625756\n",
      ".\\.git\\objects\\fd\\77660802c1c28dd2f77e7774f3d2b802c1ca45\n",
      ".\\.git\\objects\\ff\\3233c176e90bd8caed6d4dd830603469307110\n",
      ".\\.git\\objects\\pack\\pack-1f09828d7b4834060f6ac901c43221a9da94d7de.idx\n",
      ".\\.git\\objects\\pack\\pack-1f09828d7b4834060f6ac901c43221a9da94d7de.pack\n",
      ".\\.git\\objects\\pack\\pack-1f09828d7b4834060f6ac901c43221a9da94d7de.rev\n",
      ".\\.git\\refs\\heads\\main\n",
      ".\\.git\\refs\\remotes\\origin\\HEAD\n",
      ".\\.git\\refs\\remotes\\origin\\main\n",
      ".\\.idea\\.gitignore\n",
      ".\\.idea\\kaggle-jigsaw.iml\n",
      ".\\.idea\\misc.xml\n",
      ".\\.idea\\modules.xml\n",
      ".\\.idea\\vcs.xml\n",
      ".\\.idea\\workspace.xml\n",
      ".\\.idea\\inspectionProfiles\\profiles_settings.xml\n",
      ".\\.idea\\inspectionProfiles\\Project_Default.xml\n",
      ".\\.idea\\shelf\\Uncommitted_changes_before_Update_at_8_2_2025_8_38_PM__Changes_.xml\n",
      ".\\.idea\\shelf\\Uncommitted_changes_before_Update_at_8_6_2025_8_46_PM__Changes_.xml\n",
      ".\\.idea\\shelf\\Uncommitted_changes_before_Update_at_8_2_2025_8_38_PM_[Changes]\\shelved.patch\n",
      ".\\.idea\\shelf\\Uncommitted_changes_before_Update_at_8_6_2025_8_46_PM_[Changes]\\shelved.patch\n",
      ".\\__pycache__\\Jigsaw.cpython-312.pyc\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T13:37:01.361490Z",
     "start_time": "2025-08-07T13:36:56.715699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch_directml\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
    "from pytorch_metric_learning.losses import SupConLoss"
   ],
   "id": "99f647c4139ba5d8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\satra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T13:37:01.547566Z",
     "start_time": "2025-08-07T13:37:01.531921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_device():\n",
    "    # Try to detect NVIDIA CUDA GPU first\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f\"Using NVIDIA CUDA GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.2f} GB\")\n",
    "        return device\n",
    "\n",
    "    # If no NVIDIA CUDA GPU, try to detect DirectML GPU\n",
    "    try:\n",
    "        if torch_directml.is_available():\n",
    "            device = torch_directml.device()\n",
    "            print(f\"Using DirectML GPU: {device}\")\n",
    "            # Add a small test to ensure it's truly usable\n",
    "            try:\n",
    "                _ = torch.tensor([1], device=device)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: DirectML device found but not usable ({e}). Falling back to CPU.\")\n",
    "                return torch.device(\"cpu\")\n",
    "            return device\n",
    "        else:\n",
    "            print(\"DirectML is NOT available.\")\n",
    "    except ImportError:\n",
    "        print(\"torch_directml not installed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking DirectML: {e}. Falling back to CPU.\")\n",
    "\n",
    "    # If neither GPU is found, fall back to CPU\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU (NVIDIA CUDA or DirectML) found. Using CPU.\")\n",
    "    return device"
   ],
   "id": "c697205d17849257",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T13:37:01.759885Z",
     "start_time": "2025-08-07T13:37:01.697715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------\n",
    "# Load and preprocess data\n",
    "# -----------------------------\n",
    "# Use Kaggle paths when running on Kaggle\n",
    "# MODEL_PATH = \"/kaggle/input/xlm-roberta-base-offline/xlm_roberta_base_offline\"\n",
    "MODEL_PATH = \"C:/Users/satra/Downloads/xlm_roberta_base_offline\"\n",
    "\n",
    "# trn = \"/kaggle/input/jigsaw-agile-community-rules/train.csv\"\n",
    "# tst = \"/kaggle/input/jigsaw-agile-community-rules/test.csv\"\n",
    "trn = \"C:/Users/satra/Downloads/jigsaw-agile-community-rules/train.csv\"\n",
    "tst = \"C:/Users/satra/Downloads/jigsaw-agile-community-rules/test.csv\"\n",
    "df_trn = pd.read_csv(trn)\n",
    "df_trn = df_trn.sample(frac=.01, random_state=42).reset_index(drop=True)\n",
    "\n",
    "df_tst = pd.read_csv(tst)\n",
    "\n",
    "\n",
    "def fill_empty_examples_pandas(df):\n",
    "    example_cols = ['positive_example_1', 'positive_example_2', 'negative_example_1', 'negative_example_2']\n",
    "    for col in example_cols:\n",
    "        df[col] = df[col].fillna('').astype(str)\n",
    "\n",
    "    df['positive_example_1'] = df['positive_example_1'].mask(df['positive_example_1'] == '', df['positive_example_2'])\n",
    "    df['positive_example_2'] = df['positive_example_2'].mask(df['positive_example_2'] == '', df['positive_example_1'])\n",
    "\n",
    "    df['negative_example_1'] = df['negative_example_1'].mask(df['negative_example_1'] == '', df['negative_example_2'])\n",
    "    df['negative_example_2'] = df['negative_example_2'].mask(df['negative_example_2'] == '', df['negative_example_1'])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def getText(value):\n",
    "    return str(value) if pd.notna(value) else ''\n",
    "\n",
    "\n",
    "def extract_texts(row):\n",
    "    return {\n",
    "        \"body\": getText(row[\"body\"]),\n",
    "        \"rule\": getText(row[\"rule\"]),\n",
    "        \"subreddit\": getText(row[\"subreddit\"]),\n",
    "        \"pos1\": f\"{getText(row['positive_example_1'])}\",\n",
    "        \"pos2\": f\"{getText(row['positive_example_2'])}\",\n",
    "        \"neg1\": f\"{getText(row['negative_example_1'])}\",\n",
    "        \"neg2\": f\"{getText(row['negative_example_2'])}\",\n",
    "    }\n",
    "\n",
    "df_trn = fill_empty_examples_pandas(df_trn)\n",
    "df_tst = fill_empty_examples_pandas(df_tst)\n",
    "\n",
    "df_trn[\"inputs\"] = df_trn.apply(extract_texts, axis=1)\n",
    "\n",
    "df_tst['text_to_classify'] = df_tst['body'].apply(getText)\n",
    "df_tst[\"inputs\"] = df_tst.apply(extract_texts, axis=1)\n",
    "\n",
    "text_feature_cols = [\n",
    "    'body',\n",
    "    'rule',\n",
    "    'subreddit',\n",
    "    'positive_example_1',\n",
    "    'positive_example_2',\n",
    "    'negative_example_1',\n",
    "    'negative_example_2'\n",
    "]\n",
    "\n",
    "print(\"--- Comprehensive NaN Inspection for All Text Feature Columns ---\")\n",
    "\n",
    "# Count NaNs for each text feature column\n",
    "print(\"NaN Counts per Text Feature Column ---\")\n",
    "print(df_trn[text_feature_cols].isnull().sum())\n",
    "\n",
    "# Analyze rows with NaNs in 'body' (most critical)\n",
    "print(\"Analysis for 'body' column NaNs ---\")\n",
    "body_nan_rows = df_trn[df_trn['body'].isnull()]\n",
    "if not body_nan_rows.empty:\n",
    "    print(f\"Number of rows with NaN in 'body': {len(body_nan_rows)}\")\n",
    "    print(\"Rule violation distribution for rows with NaN in 'body':\")\n",
    "    print(body_nan_rows['rule_violation'].value_counts(normalize=True))\n",
    "else:\n",
    "    print(\"No NaN values found in 'body' column.\")\n",
    "\n",
    "# Analyze rows with NaNs in 'rule'\n",
    "print(\"Analysis for 'rule' column NaNs ---\")\n",
    "rule_nan_rows = df_trn[df_trn['rule'].isnull()]\n",
    "if not rule_nan_rows.empty:\n",
    "    print(f\"Number of rows with NaN in 'rule': {len(rule_nan_rows)}\")\n",
    "    print(\"Rule violation distribution for rows with NaN in 'rule':\")\n",
    "    print(rule_nan_rows['rule_violation'].value_counts(normalize=True))\n",
    "else:\n",
    "    print(\"No NaN values found in 'rule' column.\")\n",
    "\n",
    "# Analyze rows with NaNs in 'subreddit'\n",
    "print(\"Analysis for 'subreddit' column NaNs ---\")\n",
    "subreddit_nan_rows = df_trn[df_trn['subreddit'].isnull()]\n",
    "if not subreddit_nan_rows.empty:\n",
    "    print(f\"Number of rows with NaN in 'subreddit': {len(subreddit_nan_rows)}\")\n",
    "    print(\"Rule violation distribution for rows with NaN in 'subreddit':\")\n",
    "    print(subreddit_nan_rows['rule_violation'].value_counts(normalize=True))\n",
    "else:\n",
    "    print(\"No NaN values found in any example column.\")\n",
    "\n",
    "# Overall rule_violation distribution (for comparison)\n",
    "print(f\"Overall rule_violation distribution: ---\")\n",
    "print(df_trn['rule_violation'].value_counts(normalize=True))"
   ],
   "id": "bfd52a0f8f745a4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Comprehensive NaN Inspection for All Text Feature Columns ---\n",
      "NaN Counts per Text Feature Column ---\n",
      "body                  0\n",
      "rule                  0\n",
      "subreddit             0\n",
      "positive_example_1    0\n",
      "positive_example_2    0\n",
      "negative_example_1    0\n",
      "negative_example_2    0\n",
      "dtype: int64\n",
      "Analysis for 'body' column NaNs ---\n",
      "No NaN values found in 'body' column.\n",
      "Analysis for 'rule' column NaNs ---\n",
      "No NaN values found in 'rule' column.\n",
      "Analysis for 'subreddit' column NaNs ---\n",
      "No NaN values found in any example column.\n",
      "Overall rule_violation distribution: ---\n",
      "rule_violation\n",
      "0    0.55\n",
      "1    0.45\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T13:37:01.806902Z",
     "start_time": "2025-08-07T13:37:01.794740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "N_EPOCHS = 2\n",
    "k_folds = 5\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset\n",
    "# -----------------------------\n",
    "class MultiInputDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=128, is_test=False): # Renamed df_trn to df for generality\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        item = {}\n",
    "        for field in [\"text_to_classify\", \"rule\", \"subreddit\"]:\n",
    "            encoded = self.tokenizer(\n",
    "                row[field],\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                max_length=self.max_len,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "\n",
    "            for key in encoded:\n",
    "                item[f\"{field}_{key}\"] = encoded[key].squeeze(0)\n",
    "        if not self.is_test:\n",
    "          item[\"label\"] = torch.tensor(row[\"rule_violation\"], dtype=torch.float32)\n",
    "        return item\n",
    "\n",
    "# -----------------------------\n",
    "# Model\n",
    "# -----------------------------\n",
    "class MultiInputBERT(nn.Module):\n",
    "    def __init__(self, model_name=MODEL_PATH, embedding_dim=256): # Added embedding_dim\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Projection head for contrastive learning\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(768 * 3, 512), # Input is concatenated CLS tokens\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, embedding_dim) # Output embedding for contrastive loss\n",
    "        )\n",
    "        \n",
    "        # Original classifier for downstream task (can be re-attached or fine-tuned)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 1) # Classifier takes the projected embedding\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        cls_outputs = []\n",
    "        for field in [\"text_to_classify\", \"rule\", \"subreddit\"]:\n",
    "            out = self.bert(\n",
    "                input_ids=inputs[f\"{field}_input_ids\"],\n",
    "                attention_mask=inputs[f\"{field}_attention_mask\"]\n",
    "            )\n",
    "            cls_outputs.append(out.last_hidden_state[:, 0])  # CLS token\n",
    "        \n",
    "        x = torch.cat(cls_outputs, dim=1)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Get embeddings from projection head\n",
    "        embeddings = self.projection_head(x)\n",
    "        \n",
    "        # Get logits from classifier (for downstream task)\n",
    "        logits = self.classifier(embeddings)\n",
    "        \n",
    "        return logits, embeddings # Return both"
   ],
   "id": "8ab276540d382932",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T14:07:52.404247Z",
     "start_time": "2025-08-07T13:37:01.840977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------\n",
    "# Training and Evaluation\n",
    "# -----------------------------\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = get_device()\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "oof_preds = np.zeros(len(df_trn))\n",
    "test_preds_folds = [] # This is correct\n",
    "\n",
    "for fold, (train_idx_orig, val_idx_orig) in enumerate(skf.split(df_trn, df_trn[\"rule_violation\"])):\n",
    "    print(f\"----- Fold {fold+1} -----\")\n",
    "    # train_df = df_trn.iloc[train_idx].reset_index(drop=True)\n",
    "\n",
    "    # Create original train and validation DataFrames for this fold\n",
    "    # These are the original body, rules, subreddits, and examples\n",
    "    fold_train_df_orig = df_trn.iloc[train_idx_orig].reset_index(drop=True)\n",
    "    fold_val_df_orig = df_trn.iloc[val_idx_orig].reset_index(drop=True)\n",
    "\n",
    "    # Expand the tarining data for this fold\n",
    "    expanded_train_data = []\n",
    "    for idx, row in fold_train_df_orig.iterrows():\n",
    "        rule_text = getText(row['rule'])\n",
    "        subreddit_text = getText(row['subreddit'])\n",
    "        # Add original body as a training sample\n",
    "        expanded_train_data.append({\n",
    "            'text_to_classify': getText(row['body']),\n",
    "            'rule': rule_text,\n",
    "            'subreddit': subreddit_text,\n",
    "            'rule_violation': row['rule_violation']\n",
    "        })\n",
    "        # Add positive examples\n",
    "        expanded_train_data.append({\n",
    "            'text_to_classify': getText(row['positive_example_1']),\n",
    "            'rule': rule_text,\n",
    "            'subreddit': subreddit_text,\n",
    "            'rule_violation': 1.0\n",
    "        })\n",
    "        expanded_train_data.append({\n",
    "            'text_to_classify': getText(row['positive_example_2']),\n",
    "            'rule': rule_text,\n",
    "            'subreddit': subreddit_text,\n",
    "            'rule_violation': 1.0\n",
    "        })\n",
    "        # Add negative examples\n",
    "        expanded_train_data.append({\n",
    "            'text_to_classify': getText(row['negative_example_1']),\n",
    "            'rule': rule_text,\n",
    "            'subreddit': subreddit_text,\n",
    "            'rule_violation': 0.0\n",
    "        })\n",
    "        expanded_train_data.append({\n",
    "            'text_to_classify': getText(row['negative_example_2']),\n",
    "            'rule': rule_text,\n",
    "            'subreddit': subreddit_text,\n",
    "            'rule_violation': 0.0\n",
    "        })\n",
    "\n",
    "    # Create the expanded training DataFrame for this fold\n",
    "    fold_train_df_expanded = pd.DataFrame(expanded_train_data)\n",
    "    fold_train_df_expanded = fold_train_df_expanded[fold_train_df_expanded['text_to_classify'] != ''].reset_index(drop=True)\n",
    "\n",
    "    # 3. Prepare the VALIDATION data for this fold (using original body)\n",
    "    # Map 'body' to 'text_to_classify' for the validation set\n",
    "    fold_val_df_for_model = fold_val_df_orig.copy()\n",
    "    fold_val_df_for_model['text_to_classify'] = fold_val_df_for_model['body']\n",
    "\n",
    "    # 4. Create Datasets and DataLoaders\n",
    "    train_dataset = MultiInputDataset(fold_train_df_expanded, tokenizer) # Train on expanded data\n",
    "    val_dataset = MultiInputDataset(fold_val_df_for_model, tokenizer) # Validate on original body\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8) # Use a consistent batch size\n",
    "\n",
    "    test_loader = DataLoader(MultiInputDataset(df_tst, tokenizer, is_test=True), batch_size=8, shuffle=False)\n",
    "\n",
    "\n",
    "    model = MultiInputBERT().to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-6)\n",
    "    \n",
    "    # Change criterion to SupervisedContrastiveLoss\n",
    "    criterion = SupConLoss(temperature=0.07) # Common temperature value\n",
    "    \n",
    "    num_training_steps_per_fold = len(train_loader) * N_EPOCHS\n",
    "    num_warmup_steps_per_fold = int(num_training_steps_per_fold * 0.05)\n",
    "\n",
    "    # Initialize the scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=num_warmup_steps_per_fold,\n",
    "        num_training_steps=num_training_steps_per_fold\n",
    "    )\n",
    "\n",
    "    # Training Loop for this fold\n",
    "    best_auc = -1.0 # Track best AUC for this fold\n",
    "    best_model_state = None # To save the best model for this fold\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n",
    "            inputs = {k: v.to(device) for k, v in batch.items() if k != \"label\"}\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Get both logits and embeddings\n",
    "            logits, embeddings = model(inputs) \n",
    "            \n",
    "            # Calculate contrastive loss\n",
    "            loss = criterion(embeddings, labels) \n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1} Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "        # Eval (for monitoring, still using AUC on classification task)\n",
    "        model.eval()\n",
    "        preds_raw, labels_all = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=f\"Validating Epoch {epoch+1}\"):\n",
    "                inputs = {k: v.to(device) for k, v in batch.items() if k != \"label\"}\n",
    "                labels = batch[\"label\"].to(device)\n",
    "                \n",
    "                # Get logits for evaluation\n",
    "                logits, _ = model(inputs) \n",
    "                logits = logits.squeeze(-1) # Squeeze to [batch_size]\n",
    "\n",
    "                probs = torch.sigmoid(logits).detach().cpu().tolist()\n",
    "                preds_raw.extend(probs)\n",
    "                labels_all.extend(labels.cpu().tolist())\n",
    "\n",
    "            # Hard labels (for classification report, optional)\n",
    "            preds = [int(p > 0.5) for p in preds_raw]\n",
    "\n",
    "        # Print metrics\n",
    "        print(classification_report(labels_all, preds, digits=3, zero_division=0))\n",
    "\n",
    "        curr_auc = roc_auc_score(labels_all, preds_raw)\n",
    "        print(f\"AUC Score: {curr_auc:.4f}\")\n",
    "\n",
    "        # Save the best model for this fold based on validation AUC\n",
    "        if curr_auc > best_auc:\n",
    "            best_auc = curr_auc\n",
    "            best_model_state = model.state_dict() # Save model weights\n",
    "            print(f\"  -> New best Val AUC for Fold {fold+1}: {best_auc:.4f}\")\n",
    "\n",
    "    # 6. Load best model state for this fold\n",
    "    model.load_state_dict(best_model_state) # Use best_model_state\n",
    "    print(f\"Fold {fold+1} Best Val AUC: {best_auc:.4f}\")\n",
    "\n",
    "    # Make OOF predictions for this fold's validation set\n",
    "    model.eval()\n",
    "    fold_val_preds_list = []\n",
    "    fold_val_true_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f\"Fold {fold + 1} OOF Prediction\"):\n",
    "            inputs = {k: v.to(device) for k, v in batch.items() if k != \"label\"}\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            logits, _ = model(inputs)\n",
    "            logits = logits.squeeze(-1)  # Squeeze to [batch_size]\n",
    "            probs = torch.sigmoid(logits).detach().cpu().tolist()\n",
    "            fold_val_preds_list.extend(probs)\n",
    "            fold_val_true_list.extend(labels.cpu().tolist())\n",
    "\n",
    "    # Sanity check: Calculate AUC for this fold's OOF predictions\n",
    "    oof_fold_auc_check = roc_auc_score(fold_val_true_list, fold_val_preds_list)\n",
    "    print(f\"Fold {fold + 1} OOF AUC Check: {oof_fold_auc_check:.4f} (This is the true validation AUC for this fold)\")\n",
    "\n",
    "    # Assign predictions to the correct indices in the global oof_preds array\n",
    "    oof_preds[val_idx_orig] = np.array(fold_val_preds_list)  # Use val_idx_orig from kf.split\n",
    "    # Make predictions on the TEST set using this fold's best model\n",
    "    test_fold_preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=f\"Fold {fold + 1} Test Prediction\"):\n",
    "            inputs = {k: v.to(device) for k, v in batch.items()}\n",
    "            logits, _ = model(inputs)\n",
    "            logits = logits.squeeze(-1)  # Squeeze to [batch_size]\n",
    "            probs = torch.sigmoid(logits).detach().cpu().tolist()\n",
    "            test_fold_preds.extend(probs)\n",
    "\n",
    "    test_preds_folds.append(test_fold_preds)  # Store test predictions from this fold\n",
    "\n",
    "# -----------------------------\n",
    "# Final Calculation and Submission\n",
    "# -----------------------------\n",
    "overall_oof_auc = roc_auc_score(df_trn[\"rule_violation\"], oof_preds)\n",
    "print(f\"Overall {k_folds}-Fold OOF AUC: {overall_oof_auc:.4f} ---\")\n",
    "\n",
    "# Average test predictions across all folds\n",
    "final_test_predictions = np.mean(test_preds_folds, axis=0)\n",
    "\n",
    "# Create final submission file\n",
    "submission = pd.DataFrame({\n",
    "    \"row_id\": df_tst[\"row_id\"],\n",
    "    \"rule_violation\": final_test_predictions\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False) # Save with a distinct name\n",
    "print(\"K-Fold multi-input submission.csv created successfully!\")\n",
    "print(submission.head(10))"
   ],
   "id": "e0eb37c47a02b1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DirectML GPU: privateuseone:0\n",
      "----- Fold 1 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at C:/Users/satra/Downloads/xlm_roberta_base_offline and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Training Epoch 1:   0%|          | 0/10 [00:00<?, ?it/s]C:\\Users\\satra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1562: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "C:\\Users\\satra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\optim\\adamw.py:529: UserWarning: The operator 'aten::lerp.Scalar_out' is not currently supported on the DML backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at C:\\__w\\1\\s\\pytorch-directml-plugin\\torch_directml\\csrc\\dml\\dml_cpu_fallback.cpp:17.)\n",
      "  torch._foreach_lerp_(device_exp_avgs, device_grads, 1 - beta1)\n",
      "Training Epoch 1: 100%|██████████| 10/10 [02:47<00:00, 16.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 2.9567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 1: 100%|██████████| 1/1 [00:03<00:00,  3.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.000     0.000     0.000         2\n",
      "         1.0      0.500     1.000     0.667         2\n",
      "\n",
      "    accuracy                          0.500         4\n",
      "   macro avg      0.250     0.500     0.333         4\n",
      "weighted avg      0.250     0.500     0.333         4\n",
      "\n",
      "AUC Score: 0.5000\n",
      "  -> New best Val AUC for Fold 1: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2:   0%|          | 0/10 [00:00<?, ?it/s]C:\\Users\\satra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1562: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training Epoch 2: 100%|██████████| 10/10 [02:48<00:00, 16.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 3.1502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 2: 100%|██████████| 1/1 [00:03<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.000     0.000     0.000         2\n",
      "         1.0      0.500     1.000     0.667         2\n",
      "\n",
      "    accuracy                          0.500         4\n",
      "   macro avg      0.250     0.500     0.333         4\n",
      "weighted avg      0.250     0.500     0.333         4\n",
      "\n",
      "AUC Score: 0.0000\n",
      "Fold 1 Best Val AUC: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 OOF Prediction:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\satra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1562: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Fold 1 OOF Prediction: 100%|██████████| 1/1 [00:03<00:00,  3.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 OOF AUC Check: 0.0000 (This is the true validation AUC for this fold)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Test Prediction:   0%|          | 0/2 [00:00<?, ?it/s]C:\\Users\\satra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1562: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Fold 1 Test Prediction: 100%|██████████| 2/2 [00:07<00:00,  3.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Fold 2 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at C:/Users/satra/Downloads/xlm_roberta_base_offline and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Training Epoch 1:   0%|          | 0/10 [00:00<?, ?it/s]C:\\Users\\satra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1562: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training Epoch 1: 100%|██████████| 10/10 [03:08<00:00, 18.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 3.2391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 1: 100%|██████████| 1/1 [00:03<00:00,  3.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.000     0.000     0.000         2\n",
      "         1.0      0.500     1.000     0.667         2\n",
      "\n",
      "    accuracy                          0.500         4\n",
      "   macro avg      0.250     0.500     0.333         4\n",
      "weighted avg      0.250     0.500     0.333         4\n",
      "\n",
      "AUC Score: 0.5000\n",
      "  -> New best Val AUC for Fold 2: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2:   0%|          | 0/10 [00:00<?, ?it/s]C:\\Users\\satra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1562: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training Epoch 2: 100%|██████████| 10/10 [03:21<00:00, 20.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 2.9362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 2: 100%|██████████| 1/1 [00:03<00:00,  3.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.000     0.000     0.000         2\n",
      "         1.0      0.500     1.000     0.667         2\n",
      "\n",
      "    accuracy                          0.500         4\n",
      "   macro avg      0.250     0.500     0.333         4\n",
      "weighted avg      0.250     0.500     0.333         4\n",
      "\n",
      "AUC Score: 0.5000\n",
      "Fold 2 Best Val AUC: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 OOF Prediction:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\satra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1562: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Fold 2 OOF Prediction: 100%|██████████| 1/1 [00:03<00:00,  3.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 OOF AUC Check: 0.5000 (This is the true validation AUC for this fold)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Test Prediction:   0%|          | 0/2 [00:00<?, ?it/s]C:\\Users\\satra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1562: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Fold 2 Test Prediction: 100%|██████████| 2/2 [00:07<00:00,  3.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Fold 3 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at C:/Users/satra/Downloads/xlm_roberta_base_offline and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Training Epoch 1:   0%|          | 0/10 [00:00<?, ?it/s]C:\\Users\\satra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1562: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training Epoch 1: 100%|██████████| 10/10 [02:55<00:00, 17.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 3.2165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 1: 100%|██████████| 1/1 [00:03<00:00,  3.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.000     0.000     0.000         2\n",
      "         1.0      0.500     1.000     0.667         2\n",
      "\n",
      "    accuracy                          0.500         4\n",
      "   macro avg      0.250     0.500     0.333         4\n",
      "weighted avg      0.250     0.500     0.333         4\n",
      "\n",
      "AUC Score: 0.5000\n",
      "  -> New best Val AUC for Fold 3: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2:   0%|          | 0/10 [00:00<?, ?it/s]C:\\Users\\satra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1562: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training Epoch 2: 100%|██████████| 10/10 [03:05<00:00, 18.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 3.3106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 2: 100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.000     0.000     0.000         2\n",
      "         1.0      0.500     1.000     0.667         2\n",
      "\n",
      "    accuracy                          0.500         4\n",
      "   macro avg      0.250     0.500     0.333         4\n",
      "weighted avg      0.250     0.500     0.333         4\n",
      "\n",
      "AUC Score: 0.5000\n",
      "Fold 3 Best Val AUC: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 OOF Prediction:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\satra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1562: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Fold 3 OOF Prediction: 100%|██████████| 1/1 [00:03<00:00,  3.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 OOF AUC Check: 0.5000 (This is the true validation AUC for this fold)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Test Prediction:   0%|          | 0/2 [00:00<?, ?it/s]C:\\Users\\satra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1562: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Fold 3 Test Prediction: 100%|██████████| 2/2 [00:07<00:00,  3.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Fold 4 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at C:/Users/satra/Downloads/xlm_roberta_base_offline and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Training Epoch 1:   0%|          | 0/10 [00:00<?, ?it/s]C:\\Users\\satra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1562: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training Epoch 1: 100%|██████████| 10/10 [02:42<00:00, 16.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 3.1020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 1: 100%|██████████| 1/1 [00:03<00:00,  3.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      1.000     0.500     0.667         2\n",
      "         1.0      0.667     1.000     0.800         2\n",
      "\n",
      "    accuracy                          0.750         4\n",
      "   macro avg      0.833     0.750     0.733         4\n",
      "weighted avg      0.833     0.750     0.733         4\n",
      "\n",
      "AUC Score: 0.5000\n",
      "  -> New best Val AUC for Fold 4: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2:   0%|          | 0/10 [00:00<?, ?it/s]C:\\Users\\satra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1562: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training Epoch 2: 100%|██████████| 10/10 [02:41<00:00, 16.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 3.1916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 2: 100%|██████████| 1/1 [00:03<00:00,  3.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      1.000     0.500     0.667         2\n",
      "         1.0      0.667     1.000     0.800         2\n",
      "\n",
      "    accuracy                          0.750         4\n",
      "   macro avg      0.833     0.750     0.733         4\n",
      "weighted avg      0.833     0.750     0.733         4\n",
      "\n",
      "AUC Score: 0.5000\n",
      "Fold 4 Best Val AUC: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 OOF Prediction:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\satra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1562: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Fold 4 OOF Prediction: 100%|██████████| 1/1 [00:03<00:00,  3.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 OOF AUC Check: 0.5000 (This is the true validation AUC for this fold)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 Test Prediction:   0%|          | 0/2 [00:00<?, ?it/s]C:\\Users\\satra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1562: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Fold 4 Test Prediction: 100%|██████████| 2/2 [00:07<00:00,  3.76s/it]\n",
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at C:/Users/satra/Downloads/xlm_roberta_base_offline and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Fold 5 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:   0%|          | 0/10 [00:00<?, ?it/s]C:\\Users\\satra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1562: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training Epoch 1: 100%|██████████| 10/10 [02:39<00:00, 15.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 2.6613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 1: 100%|██████████| 1/1 [00:03<00:00,  3.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.000     0.000     0.000         3\n",
      "         1.0      0.250     1.000     0.400         1\n",
      "\n",
      "    accuracy                          0.250         4\n",
      "   macro avg      0.125     0.500     0.200         4\n",
      "weighted avg      0.062     0.250     0.100         4\n",
      "\n",
      "AUC Score: 1.0000\n",
      "  -> New best Val AUC for Fold 5: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2:   0%|          | 0/10 [00:00<?, ?it/s]C:\\Users\\satra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1562: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Training Epoch 2: 100%|██████████| 10/10 [03:00<00:00, 18.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 3.3046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 2: 100%|██████████| 1/1 [00:03<00:00,  3.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.000     0.000     0.000         3\n",
      "         1.0      0.250     1.000     0.400         1\n",
      "\n",
      "    accuracy                          0.250         4\n",
      "   macro avg      0.125     0.500     0.200         4\n",
      "weighted avg      0.062     0.250     0.100         4\n",
      "\n",
      "AUC Score: 1.0000\n",
      "Fold 5 Best Val AUC: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5 OOF Prediction:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\satra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1562: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Fold 5 OOF Prediction: 100%|██████████| 1/1 [00:03<00:00,  3.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 OOF AUC Check: 1.0000 (This is the true validation AUC for this fold)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5 Test Prediction:   0%|          | 0/2 [00:00<?, ?it/s]C:\\Users\\satra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1562: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Fold 5 Test Prediction: 100%|██████████| 2/2 [00:07<00:00,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall 5-Fold OOF AUC: 0.4141 ---\n",
      "K-Fold multi-input submission.csv created successfully!\n",
      "   row_id  rule_violation\n",
      "0    2029        0.536665\n",
      "1    2030        0.533946\n",
      "2    2031        0.536456\n",
      "3    2032        0.536439\n",
      "4    2033        0.536737\n",
      "5    2034        0.536973\n",
      "6    2035        0.536562\n",
      "7    2036        0.536686\n",
      "8    2037        0.536687\n",
      "9    2038        0.536781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 13121456,
     "isSourceIdPinned": false,
     "sourceId": 94635,
     "sourceType": "competition"
    },
    {
     "datasetId": 7984956,
     "sourceId": 12636496,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15818.859754,
   "end_time": "2025-08-06T07:46:47.714661",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-06T03:23:08.854907",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
