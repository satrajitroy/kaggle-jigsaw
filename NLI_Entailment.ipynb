{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-16T14:35:55.305727Z",
     "start_time": "2025-08-16T14:35:00.617044Z"
    }
   },
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
    "save_path = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "NLI_BACKBONE = save_path\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\satra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('paraphrase-multilingual-MiniLM-L12-v2\\\\tokenizer_config.json',\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2\\\\special_tokens_map.json',\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2\\\\unigram.json',\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2\\\\added_tokens.json',\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2\\\\tokenizer.json')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T14:36:19.458012Z",
     "start_time": "2025-08-16T14:36:10.746562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========= Setup (CPU-friendly) =========\n",
    "import os, numpy as np, pandas as pd\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"4\"\n",
    "\n",
    "from sentence_transformers import CrossEncoder\n",
    "from scipy.special import softmax\n",
    "\n",
    "# Pick an NLI cross-encoder (English):\n",
    "# NLI_BACKBONE = \"C:/Users/satra/PycharmProjects/kaggle-jigsaw/nli-deberta-v3-local\"\n",
    "\n",
    "# If you need multilingual, try:\n",
    "# NLI_BACKBONE = \"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\"\n",
    "\n",
    "# ========= Data =========\n",
    "TEST_CSV = \"C:/Users/satra/PycharmProjects/kaggle-jigsaw/test.csv\"\n",
    "df_test = pd.read_csv(TEST_CSV)\n",
    "\n",
    "def make_hypothesis(rule, subreddit=None):\n",
    "    rule = str(rule)\n",
    "    sub  = str(subreddit) if pd.notna(subreddit) else \"\"\n",
    "    return f\"This post violates the rule: {rule}.\" if not sub else \\\n",
    "           f\"This post violates the rule: {rule} in subreddit r/{sub}.\"\n",
    "\n",
    "premises   = df_test[\"body\"].astype(str).tolist()\n",
    "hypotheses = [make_hypothesis(r, s) for r, s in zip(df_test[\"rule\"], df_test[\"subreddit\"])]\n",
    "pairs = list(zip(premises, hypotheses))\n",
    "\n",
    "# ========= Model =========\n",
    "# If you uploaded a local copy as a Kaggle Dataset, pass that folder path instead.\n",
    "nli = CrossEncoder(NLI_BACKBONE)  # CPU by default\n",
    "\n",
    "# Batched predict (adjust batch_size if RAM allows)\n",
    "logits = nli.predict(pairs, convert_to_numpy=True, show_progress_bar=True, batch_size=64)\n",
    "\n",
    "# Most NLI cross-encoders return 3 logits: [entailment, neutral, contradiction].\n",
    "# If yours differs, print logits.shape and adjust the index below.\n",
    "probs = softmax(logits, axis=1) if logits.ndim == 2 else np.vstack([logits, 1 - logits]).T\n",
    "p_entail = probs[:, 0] if probs.shape[1] >= 3 else probs[:, 1]  # entailment column\n",
    "\n",
    "# ========= Submission =========\n",
    "sub = pd.DataFrame({\"row_id\": df_test[\"row_id\"], \"rule_violation\": p_entail.astype(float)})\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "print(\"submission.csv written\", sub.shape)\n"
   ],
   "id": "cc10d9af497a9f44",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission.csv written (10, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T14:47:26.672360Z",
     "start_time": "2025-08-16T14:36:56.034751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Use the same df you used to create val_rows earlier\n",
    "# Must contain: 'body', 'rule', 'subreddit', 'rule_violation'\n",
    "# Example: df_val = df_trn.copy()  # or however you defined your validation slice\n",
    "TRAIN_CSV = \"C:/Users/satra/PycharmProjects/kaggle-jigsaw/train.csv\"\n",
    "df_trn = pd.read_csv(TRAIN_CSV)\n",
    "df_val = df_trn.copy()  # replace with your actual validation frame\n",
    "\n",
    "# ----- Build premise/hypothesis pairs -----\n",
    "def make_hypothesis(rule, subreddit=None):\n",
    "    r = str(rule)\n",
    "    s = str(subreddit) if pd.notna(subreddit) else \"\"\n",
    "    return f\"This post violates the rule: {r}.\" if not s else \\\n",
    "           f\"This post violates the rule: {r} in subreddit r/{s}.\"\n",
    "\n",
    "premises   = df_val[\"body\"].astype(str).tolist()\n",
    "hypotheses = [make_hypothesis(r, s) for r, s in zip(df_val[\"rule\"], df_val[\"subreddit\"])]\n",
    "pairs_val  = list(zip(premises, hypotheses))\n",
    "\n",
    "y_val = df_val[\"rule_violation\"].astype(int).to_numpy()\n",
    "\n",
    "# ----- Load an NLI cross-encoder (use a local path if offline) -----\n",
    "from sentence_transformers import CrossEncoder\n",
    "from scipy.special import softmax\n",
    "\n",
    "# If you’ve saved the model locally for offline use, point to that folder instead:\n",
    "# NLI_BACKBONE = \"/kaggle/input/nli-deberta-v3-local\"\n",
    "NLI_BACKBONE = \"cross-encoder/nli-deberta-v3-base\"\n",
    "\n",
    "nli = CrossEncoder(NLI_BACKBONE)  # CPU by default\n",
    "\n",
    "# Batch predict (adjust batch_size; 64–128 is fine on Kaggle CPU)\n",
    "logits = nli.predict(pairs_val, convert_to_numpy=True, batch_size=64, show_progress_bar=True)\n",
    "\n",
    "# Most cross-encoder NLI models return 3 logits [entailment, neutral, contradiction].\n",
    "# Softmax to probabilities; pick the entailment column.\n",
    "probs = softmax(logits, axis=1) if logits.ndim == 2 else np.vstack([logits, 1 - logits]).T\n",
    "# If your model’s label order differs, change the index below accordingly:\n",
    "p_entail = probs[:, 0] if probs.shape[1] >= 3 else probs[:, 1]\n",
    "\n",
    "# ----- Evaluate -----\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "roc_auc = roc_auc_score(y_val, p_entail)\n",
    "pr_auc  = average_precision_score(y_val, p_entail)  # useful if class imbalance\n",
    "\n",
    "print(f\"NLI zero-shot ROC AUC: {roc_auc:.4f}\")\n",
    "print(f\"NLI zero-shot PR  AUC: {pr_auc:.4f}\")\n"
   ],
   "id": "f9dc86f8711909b2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 32/32 [10:28<00:00, 19.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLI zero-shot ROC AUC: 0.5803\n",
      "NLI zero-shot PR  AUC: 0.5996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:10:03.018197Z",
     "start_time": "2025-08-16T14:57:35.483433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import CrossEncoder\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "# ---------- 1) Hypothesis builders ----------\n",
    "def hyp_with_examples(rule, sub=None, pos1=\"\", pos2=\"\", neg1=\"\", neg2=\"\", negate=False):\n",
    "    \"\"\"\n",
    "    Builds a short, information-dense hypothesis.\n",
    "    negate=False  -> \"This post violates the rule ...\"\n",
    "    negate=True   -> \"This post does NOT violate the rule ...\"\n",
    "    \"\"\"\n",
    "    rule = str(rule or \"\")\n",
    "    sub  = str(sub or \"\")\n",
    "    base = \"does NOT violate\" if negate else \"violates\"\n",
    "    sub_txt = f\" in subreddit r/{sub}\" if sub else \"\"\n",
    "    # keep examples concise; they often help zero-shot NLI\n",
    "    pos_bits = [str(x).strip() for x in (pos1, pos2) if isinstance(x, str) and x.strip()]\n",
    "    neg_bits = [str(x).strip() for x in (neg1, neg2) if isinstance(x, str) and x.strip()]\n",
    "    extra = []\n",
    "    if pos_bits: extra.append(\"e.g. \" + \" | \".join(pos_bits))\n",
    "    if neg_bits: extra.append(\"counterexamples: \" + \" | \".join(neg_bits))\n",
    "    extra_txt = (\" \" + \" \".join(extra)) if extra else \"\"\n",
    "    return f\"This post {base} the rule{sub_txt}: {rule}.{extra_txt}\".strip()\n",
    "\n",
    "# ---------- 2) Robust scorer ----------\n",
    "def score_pairs(nli: CrossEncoder, premises, hypotheses, batch_size=64):\n",
    "    \"\"\"\n",
    "    Returns (entail, neutral, contradiction) probabilities as arrays.\n",
    "    Works with common SBERT CrossEncoder NLI heads.\n",
    "    \"\"\"\n",
    "    logits = nli.predict(list(zip(premises, hypotheses)),\n",
    "                         convert_to_numpy=True, show_progress_bar=True, batch_size=batch_size)\n",
    "\n",
    "    # Convert to probs\n",
    "    probs = softmax(logits, axis=1) if logits.ndim == 2 else np.vstack([logits, 1-logits]).T\n",
    "\n",
    "    # Try to locate label indices from config if present\n",
    "    entail_idx = 0\n",
    "    neutral_idx = 1 if probs.shape[1] >= 2 else None\n",
    "    contra_idx = 2 if probs.shape[1] >= 3 else None\n",
    "\n",
    "    try:\n",
    "        id2label = getattr(nli.model.config, \"id2label\", None)\n",
    "        if isinstance(id2label, dict) and len(id2label) == probs.shape[1]:\n",
    "            rev = {v.lower(): int(k) for k, v in id2label.items()}\n",
    "            entail_idx = rev.get(\"entailment\", entail_idx)\n",
    "            neutral_idx = rev.get(\"neutral\", neutral_idx)\n",
    "            contra_idx = rev.get(\"contradiction\", contra_idx)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    entail = probs[:, entail_idx]\n",
    "    neutral = probs[:, neutral_idx] if neutral_idx is not None else 1.0 - entail\n",
    "    contra  = probs[:, contra_idx]  if contra_idx  is not None else 1.0 - entail\n",
    "    return entail, neutral, contra\n",
    "\n",
    "# ---------- 3) End-to-end evaluation ----------\n",
    "def eval_nli_auc(\n",
    "    df_val: pd.DataFrame,\n",
    "    nli_model_path_or_name: str = NLI_BACKBONE,\n",
    "    batch_size: int = 64,\n",
    "    use_examples: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    df_val must contain: body, rule, subreddit, rule_violation,\n",
    "                         positive_example_1/2, negative_example_1/2 (if use_examples=True)\n",
    "    Returns: dict of AUCs for several combination rules, and the chosen 'p_violate' vector.\n",
    "    \"\"\"\n",
    "    # Premises and hypotheses\n",
    "    prem = df_val[\"body\"].astype(str).tolist()\n",
    "    if use_examples:\n",
    "        h1 = [hyp_with_examples(r, s, pe1,   pe2,   ne1,   ne2,   negate=False)\n",
    "              for r,s,pe1,pe2,ne1,ne2 in zip(\n",
    "                  df_val[\"rule\"], df_val[\"subreddit\"],\n",
    "                  df_val.get(\"positive_example_1\",\"\"), df_val.get(\"positive_example_2\",\"\"),\n",
    "                  df_val.get(\"negative_example_1\",\"\"), df_val.get(\"negative_example_2\",\"\"),\n",
    "              )]\n",
    "        h2 = [hyp_with_examples(r, s, pe1,   pe2,   ne1,   ne2,   negate=True)\n",
    "              for r,s,pe1,pe2,ne1,ne2 in zip(\n",
    "                  df_val[\"rule\"], df_val[\"subreddit\"],\n",
    "                  df_val.get(\"positive_example_1\",\"\"), df_val.get(\"positive_example_2\",\"\"),\n",
    "                  df_val.get(\"negative_example_1\",\"\"), df_val.get(\"negative_example_2\",\"\"),\n",
    "              )]\n",
    "    else:\n",
    "        h1 = [hyp_with_examples(r, s, negate=False) for r,s in zip(df_val[\"rule\"], df_val[\"subreddit\"])]\n",
    "        h2 = [hyp_with_examples(r, s, negate=True)  for r,s in zip(df_val[\"rule\"], df_val[\"subreddit\"])]\n",
    "\n",
    "    # Load model (use a local folder path here for offline Kaggle)\n",
    "    nli = CrossEncoder(nli_model_path_or_name)\n",
    "\n",
    "    # Score both templates\n",
    "    e1, n1, c1 = score_pairs(nli, prem, h1, batch_size=batch_size)  # 'violates'\n",
    "    e2, n2, c2 = score_pairs(nli, prem, h2, batch_size=batch_size)  # 'does NOT violate'\n",
    "\n",
    "    y = df_val[\"rule_violation\"].astype(int).to_numpy()\n",
    "\n",
    "    # Combination rules → a single \"violation\" score in [0,1]\n",
    "    p_entail_only   = e1\n",
    "    p_two_template  = 0.5 * e1 + 0.5 * (1.0 - e2)           # recommended simple combiner\n",
    "    p_sym_contrast  = 0.5 * (e1 + c2)                       # uses contradiction of \"not violate\"\n",
    "    p_diff          = (e1 - e2 + 1.0) / 2.0                 # map [-1,1] → [0,1]\n",
    "\n",
    "    # Compute metrics\n",
    "    def aucs(p):\n",
    "        return {\n",
    "            \"roc_auc\": roc_auc_score(y, p),\n",
    "            \"pr_auc\":  average_precision_score(y, p),\n",
    "        }\n",
    "\n",
    "    results = {\n",
    "        \"entail_only\":  aucs(p_entail_only),\n",
    "        \"two_template\": aucs(p_two_template),\n",
    "        \"sym_contrast\": aucs(p_sym_contrast),\n",
    "        \"diff_scaled\":  aucs(p_diff),\n",
    "    }\n",
    "\n",
    "    # Pick the best combiner by ROC AUC\n",
    "    best_name = max(results, key=lambda k: results[k][\"roc_auc\"])\n",
    "    best_p = {\"entail_only\": p_entail_only, \"two_template\": p_two_template,\n",
    "              \"sym_contrast\": p_sym_contrast, \"diff_scaled\": p_diff}[best_name]\n",
    "\n",
    "    print(\"NLI zero-shot AUCs:\")\n",
    "    for k, v in results.items():\n",
    "        print(f\"  {k:>12}  ROC {v['roc_auc']:.4f} | PR {v['pr_auc']:.4f}\")\n",
    "    print(f\"→ Using '{best_name}' as the violation score.\")\n",
    "\n",
    "    return {\"results\": results, \"p_violate\": best_p, \"best_name\": best_name}\n",
    "\n",
    "# ----------------- Usage -----------------\n",
    "# df_val = <your validation dataframe with the required columns>\n",
    "res = eval_nli_auc(df_val, nli_model_path_or_name=NLI_BACKBONE, batch_size=64, use_examples=True)\n",
    "p_violate = res[\"p_violate\"]  # single vector you can blend or submit (on test)\n"
   ],
   "id": "4f17383f4bcaebce",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 32/32 [1:03:52<00:00, 119.77s/it]\n",
      "Batches: 100%|██████████| 32/32 [1:08:33<00:00, 128.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLI zero-shot AUCs:\n",
      "   entail_only  ROC 0.4522 | PR 0.4758\n",
      "  two_template  ROC 0.5156 | PR 0.5042\n",
      "  sym_contrast  ROC 0.4982 | PR 0.5052\n",
      "   diff_scaled  ROC 0.5156 | PR 0.5042\n",
      "→ Using 'two_template' as the violation score.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T17:10:59.900373Z",
     "start_time": "2025-08-16T17:10:59.421319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import CrossEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from scipy.special import softmax\n",
    "\n",
    "def hyp_with_examples(rule, subreddit=None, pos1=\"\", pos2=\"\", neg1=\"\", neg2=\"\", negate=False):\n",
    "    base = \"does NOT violate\" if negate else \"violates\"\n",
    "    sub_txt = f\" in subreddit r/{subreddit}\" if isinstance(subreddit, str) and len(subreddit) else \"\"\n",
    "    pos_bits = [str(x).strip() for x in (pos1, pos2) if isinstance(x, str) and x.strip()]\n",
    "    neg_bits = [str(x).strip() for x in (neg1, neg2) if isinstance(x, str) and x.strip()]\n",
    "    extras = []\n",
    "    if pos_bits: extras.append(\"e.g. \" + \" | \".join(pos_bits))\n",
    "    if neg_bits: extras.append(\"counterexamples: \" + \" | \".join(neg_bits))\n",
    "    extra_txt = (\" \" + \" \".join(extras)) if extras else \"\"\n",
    "    return f\"This post {base} the rule{sub_txt}: {str(rule)}.{extra_txt}\".strip()\n",
    "\n",
    "def get_label_indices(nli):\n",
    "    # Map entail/neutral/contradiction indices from model config if available\n",
    "    e_idx, n_idx, c_idx = 0, 1, 2\n",
    "    try:\n",
    "        id2label = nli.model.config.id2label\n",
    "        rev = {v.lower(): int(k) for k, v in id2label.items()}\n",
    "        e_idx = rev.get(\"entailment\", e_idx)\n",
    "        n_idx = rev.get(\"neutral\", n_idx)\n",
    "        c_idx = rev.get(\"contradiction\", c_idx)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return e_idx, n_idx, c_idx\n",
    "\n",
    "def nli_logits(nli: CrossEncoder, pairs, batch_size=64):\n",
    "    # CrossEncoder.predict returns raw scores (logits) by default\n",
    "    return nli.predict(pairs, convert_to_numpy=True, show_progress_bar=True, batch_size=batch_size)\n",
    "\n",
    "def build_nli_features(df: pd.DataFrame, nli: CrossEncoder, batch_size=64, use_examples=True):\n",
    "    \"\"\"Return X (features) and the label y if present.\"\"\"\n",
    "    prem = df[\"body\"].astype(str).tolist()\n",
    "    if use_examples:\n",
    "        h1 = [hyp_with_examples(r,s,pe1,pe2,ne1,ne2,negate=False) for r,s,pe1,pe2,ne1,ne2 in\n",
    "              zip(df[\"rule\"], df[\"subreddit\"],\n",
    "                  df.get(\"positive_example_1\",\"\"), df.get(\"positive_example_2\",\"\"),\n",
    "                  df.get(\"negative_example_1\",\"\"), df.get(\"negative_example_2\",\"\"))]\n",
    "        h2 = [hyp_with_examples(r,s,pe1,pe2,ne1,ne2,negate=True) for r,s,pe1,pe2,ne1,ne2 in\n",
    "              zip(df[\"rule\"], df[\"subreddit\"],\n",
    "                  df.get(\"positive_example_1\",\"\"), df.get(\"positive_example_2\",\"\"),\n",
    "                  df.get(\"negative_example_1\",\"\"), df.get(\"negative_example_2\",\"\"))]\n",
    "    else:\n",
    "        h1 = [hyp_with_examples(r, s, negate=False) for r,s in zip(df[\"rule\"], df[\"subreddit\"])]\n",
    "        h2 = [hyp_with_examples(r, s, negate=True ) for r,s in zip(df[\"rule\"], df[\"subreddit\"])]\n",
    "\n",
    "    L1 = nli_logits(nli, list(zip(prem, h1)), batch_size=batch_size)  # [N, C]\n",
    "    L2 = nli_logits(nli, list(zip(prem, h2)), batch_size=batch_size)  # [N, C]\n",
    "    e_idx, n_idx, c_idx = get_label_indices(nli)\n",
    "\n",
    "    # Extract per-template logits\n",
    "    e1, n1, c1 = L1[:, e_idx], L1[:, n_idx], L1[:, c_idx]\n",
    "    e2, n2, c2 = L2[:, e_idx], L2[:, n_idx], L2[:, c_idx]\n",
    "\n",
    "    # Simple, effective feature set (logit domain)\n",
    "    X = np.column_stack([\n",
    "        e1, n1, c1, e2, n2, c2,\n",
    "        e1 - e2,               # entailment difference\n",
    "        c2 - c1,               # contradiction supports \"violate\"\n",
    "        (e1 + c2),             # symmetric support\n",
    "        (e1 - c1) + (c2 - e2), # margin\n",
    "    ])\n",
    "    y = df[\"rule_violation\"].astype(int).to_numpy() if \"rule_violation\" in df.columns else None\n",
    "    return X, y\n"
   ],
   "id": "7b508d5e8ff74708",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T19:15:25.990106Z",
     "start_time": "2025-08-16T17:11:05.542729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pick an NLI model (download once online; then save for offline)\n",
    "# For English: \"cross-encoder/nli-deberta-v3-base\"\n",
    "# For multilingual: \"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\"\n",
    "NLI_PATH = NLI_BACKBONE  # or a local folder path for offline use\n",
    "\n",
    "# 2a) Fit a tiny LR on your validation split\n",
    "from sentence_transformers import CrossEncoder\n",
    "nli = CrossEncoder(NLI_PATH)\n",
    "\n",
    "X_val, y_val = build_nli_features(df_val, nli, batch_size=64, use_examples=True)\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_val, y_val)\n",
    "\n",
    "# Check AUCs\n",
    "val_scores = lr.predict_proba(X_val)[:, 1]\n",
    "print(\"VAL  ROC AUC:\", roc_auc_score(y_val, val_scores))\n",
    "print(\"VAL  PR  AUC:\", average_precision_score(y_val, val_scores))\n",
    "\n",
    "# 2b) Apply to TEST (no labels)\n",
    "X_test, _ = build_nli_features(df_test, nli, batch_size=64, use_examples=True)\n",
    "test_scores = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "sub = pd.DataFrame({\"row_id\": df_test[\"row_id\"], \"rule_violation\": test_scores})\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "print(\"submission.csv written:\", sub.shape)\n"
   ],
   "id": "604f9371563f0371",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 32/32 [55:30<00:00, 104.07s/it]\n",
      "Batches: 100%|██████████| 32/32 [1:08:17<00:00, 128.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL  ROC AUC: 0.5855454847619584\n",
      "VAL  PR  AUC: 0.5858657099022349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:15<00:00, 15.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:16<00:00, 16.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission.csv written: (10, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
