Training Epoch 1:   0%|          | 0/191 [00:00<?, ?it/s]C:\Users\satra\PycharmProjects\Kaggle_Contest\.venv\Lib\site-packages\torch\nn\modules\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
Training Epoch 1: 100%|██████████| 191/191 [1:01:40<00:00, 19.38s/it]
Epoch 1 Loss: 0.6768
              precision    recall  f1-score   support

           0      0.635     0.792     0.705       250
           1      0.735     0.558     0.634       258

    accuracy                          0.673       508
   macro avg      0.685     0.675     0.669       508
weighted avg      0.685     0.673     0.669       508

AUC Score: 0.7710
Training Epoch 2:   0%|          | 0/191 [00:00<?, ?it/s]C:\Users\satra\PycharmProjects\Kaggle_Contest\.venv\Lib\site-packages\torch\nn\modules\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
Training Epoch 2: 100%|██████████| 191/191 [1:01:53<00:00, 19.44s/it]
Epoch 2 Loss: 0.5600
              precision    recall  f1-score   support

           0      0.857     0.720     0.783       250
           1      0.765     0.884     0.820       258

    accuracy                          0.803       508
   macro avg      0.811     0.802     0.801       508
weighted avg      0.810     0.803     0.802       508

AUC Score: 0.8610
Training Epoch 3:   0%|          | 0/191 [00:00<?, ?it/s]C:\Users\satra\PycharmProjects\Kaggle_Contest\.venv\Lib\site-packages\torch\nn\modules\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
Training Epoch 3: 100%|██████████| 191/191 [1:03:34<00:00, 19.97s/it]
Epoch 3 Loss: 0.3768
              precision    recall  f1-score   support

           0      0.774     0.848     0.809       250
           1      0.838     0.760     0.797       258

    accuracy                          0.803       508
   macro avg      0.806     0.804     0.803       508
weighted avg      0.806     0.803     0.803       508

AUC Score: 0.8657
Training Epoch 4:   0%|          | 0/191 [00:00<?, ?it/s]C:\Users\satra\PycharmProjects\Kaggle_Contest\.venv\Lib\site-packages\torch\nn\modules\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
Training Epoch 4: 100%|██████████| 191/191 [1:03:32<00:00, 19.96s/it]
Epoch 4 Loss: 0.2096
              precision    recall  f1-score   support

           0      0.818     0.684     0.745       250
           1      0.736     0.853     0.790       258

    accuracy                          0.770       508
   macro avg      0.777     0.768     0.768       508
weighted avg      0.776     0.770     0.768       508

AUC Score: 0.8542

----- Fold 2 -----
Training Epoch 1:   0%|          | 0/191 [00:00<?, ?it/s]C:\Users\satra\PycharmProjects\Kaggle_Contest\.venv\Lib\site-packages\torch\nn\modules\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
Training Epoch 1: 100%|██████████| 191/191 [1:03:07<00:00, 19.83s/it]
Epoch 1 Loss: 0.6706
              precision    recall  f1-score   support

           0      0.792     0.380     0.514       250
           1      0.599     0.903     0.720       257

    accuracy                          0.645       507
   macro avg      0.696     0.641     0.617       507
weighted avg      0.694     0.645     0.618       507

AUC Score: 0.6816
Training Epoch 2:   0%|          | 0/191 [00:00<?, ?it/s]C:\Users\satra\PycharmProjects\Kaggle_Contest\.venv\Lib\site-packages\torch\nn\modules\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
Training Epoch 2: 100%|██████████| 191/191 [1:03:05<00:00, 19.82s/it]
Epoch 2 Loss: 0.5511
              precision    recall  f1-score   support

           0      0.789     0.688     0.735       250
           1      0.730     0.821     0.773       257

    accuracy                          0.755       507
   macro avg      0.760     0.755     0.754       507
weighted avg      0.759     0.755     0.754       507

AUC Score: 0.8292
Training Epoch 3:   0%|          | 0/191 [00:00<?, ?it/s]C:\Users\satra\PycharmProjects\Kaggle_Contest\.venv\Lib\site-packages\torch\nn\modules\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
Training Epoch 3: 100%|██████████| 191/191 [1:03:25<00:00, 19.92s/it]
Epoch 3 Loss: 0.3723
              precision    recall  f1-score   support

           0      0.813     0.660     0.728       250
           1      0.720     0.852     0.781       257

    accuracy                          0.757       507
   macro avg      0.767     0.756     0.755       507
weighted avg      0.766     0.757     0.755       507

AUC Score: 0.8487
Training Epoch 4:   0%|          | 0/191 [00:00<?, ?it/s]C:\Users\satra\PycharmProjects\Kaggle_Contest\.venv\Lib\site-packages\torch\nn\modules\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
Training Epoch 4: 100%|██████████| 191/191 [1:03:05<00:00, 19.82s/it]
Epoch 4 Loss: 0.2057
              precision    recall  f1-score   support

           0      0.804     0.720     0.759       250
           1      0.753     0.829     0.789       257

    accuracy                          0.775       507
   macro avg      0.778     0.774     0.774       507
weighted avg      0.778     0.775     0.774       507

AUC Score: 0.8433

----- Fold 3 -----
Training Epoch 1:   0%|          | 0/191 [00:00<?, ?it/s]C:\Users\satra\PycharmProjects\Kaggle_Contest\.venv\Lib\site-packages\torch\nn\modules\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
Training Epoch 1: 100%|██████████| 191/191 [1:06:15<00:00, 20.82s/it]
Epoch 1 Loss: 0.6564
              precision    recall  f1-score   support

           0      0.635     0.928     0.754       249
           1      0.874     0.484     0.623       258

    accuracy                          0.702       507
   macro avg      0.754     0.706     0.689       507
weighted avg      0.756     0.702     0.687       507

AUC Score: 0.8389
Training Epoch 2:   0%|          | 0/191 [00:00<?, ?it/s]C:\Users\satra\PycharmProjects\Kaggle_Contest\.venv\Lib\site-packages\torch\nn\modules\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
Training Epoch 2: 100%|██████████| 191/191 [1:06:07<00:00, 20.77s/it]
Epoch 2 Loss: 0.4879
              precision    recall  f1-score   support

           0      0.731     0.851     0.787       249
           1      0.829     0.698     0.758       258

    accuracy                          0.773       507
   macro avg      0.780     0.775     0.772       507
weighted avg      0.781     0.773     0.772       507

AUC Score: 0.8619
Training Epoch 3:   0%|          | 0/191 [00:00<?, ?it/s]C:\Users\satra\PycharmProjects\Kaggle_Contest\.venv\Lib\site-packages\torch\nn\modules\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
Training Epoch 3: 100%|██████████| 191/191 [1:06:33<00:00, 20.91s/it]
Epoch 3 Loss: 0.3115
              precision    recall  f1-score   support

           0      0.784     0.771     0.777       249
           1      0.782     0.795     0.788       258

    accuracy                          0.783       507
   macro avg      0.783     0.783     0.783       507
weighted avg      0.783     0.783     0.783       507

AUC Score: 0.8614
Training Epoch 4:   0%|          | 0/191 [00:00<?, ?it/s]C:\Users\satra\PycharmProjects\Kaggle_Contest\.venv\Lib\site-packages\torch\nn\modules\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
Training Epoch 4: 100%|██████████| 191/191 [1:06:46<00:00, 20.98s/it]
Epoch 4 Loss: 0.1849
              precision    recall  f1-score   support

           0      0.779     0.695     0.735       249
           1      0.733     0.810     0.770       258

    accuracy                          0.753       507
   macro avg      0.756     0.752     0.752       507
weighted avg      0.756     0.753     0.753       507

AUC Score: 0.8473

----- Fold 4 -----
Training Epoch 1:   0%|          | 0/191 [00:00<?, ?it/s]C:\Users\satra\PycharmProjects\Kaggle_Contest\.venv\Lib\site-packages\torch\nn\modules\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
Training Epoch 1: 100%|██████████| 191/191 [1:06:24<00:00, 20.86s/it]
Epoch 1 Loss: 0.6745
              precision    recall  f1-score   support

           0      0.572     0.590     0.581       249
           1      0.592     0.574     0.583       258

    accuracy                          0.582       507
   macro avg      0.582     0.582     0.582       507
weighted avg      0.582     0.582     0.582       507

AUC Score: 0.7019
Training Epoch 2:   0%|          | 0/191 [00:00<?, ?it/s]C:\Users\satra\PycharmProjects\Kaggle_Contest\.venv\Lib\site-packages\torch\nn\modules\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
Training Epoch 2: 100%|██████████| 191/191 [1:06:17<00:00, 20.82s/it]
Epoch 2 Loss: 0.5243
              precision    recall  f1-score   support

           0      0.832     0.598     0.696       249
           1      0.695     0.884     0.778       258

    accuracy                          0.744       507
   macro avg      0.764     0.741     0.737       507
weighted avg      0.763     0.744     0.738       507

AUC Score: 0.8417
Training Epoch 3:   0%|          | 0/191 [00:00<?, ?it/s]C:\Users\satra\PycharmProjects\Kaggle_Contest\.venv\Lib\site-packages\torch\nn\modules\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
Training Epoch 3: 100%|██████████| 191/191 [1:06:24<00:00, 20.86s/it]
Epoch 3 Loss: 0.3512
              precision    recall  f1-score   support

           0      0.782     0.763     0.772       249
           1      0.777     0.795     0.785       258

    accuracy                          0.779       507
   macro avg      0.779     0.779     0.779       507
weighted avg      0.779     0.779     0.779       507

AUC Score: 0.8506
Training Epoch 4:   0%|          | 0/191 [00:00<?, ?it/s]C:\Users\satra\PycharmProjects\Kaggle_Contest\.venv\Lib\site-packages\torch\nn\modules\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
Training Epoch 4: 100%|██████████| 191/191 [1:08:09<00:00, 21.41s/it]
Epoch 4 Loss: 0.2103
              precision    recall  f1-score   support

           0      0.789     0.735     0.761       249
           1      0.760     0.810     0.784       258

    accuracy                          0.773       507
   macro avg      0.774     0.773     0.773       507
weighted avg      0.774     0.773     0.773       507

AUC Score: 0.8465
C:\Users\satra\PycharmProjects\Kaggle_Contest\.venv\Lib\site-packages\torch\nn\modules\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
   row_id  rule_violation
0    2029        0.158793
1    2030        0.803769
2    2031        0.260937
3    2032        0.847930
4    2033        0.886439
5    2034        0.095888
6    2035        0.863526
7    2036        0.111181
8    2037        0.087672
9    2038        0.860655

Process finished with exit code 0
