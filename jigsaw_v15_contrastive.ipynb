{
 "cells": [
  {
   "cell_type": "code",
   "id": "5c2c86b6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-03T14:12:00.340282Z",
     "iopub.status.busy": "2025-08-03T14:12:00.339614Z",
     "iopub.status.idle": "2025-08-03T14:12:02.002071Z",
     "shell.execute_reply": "2025-08-03T14:12:02.000970Z"
    },
    "papermill": {
     "duration": 1.66713,
     "end_time": "2025-08-03T14:12:02.003545",
     "exception": false,
     "start_time": "2025-08-03T14:12:00.336415",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-08-07T14:12:09.861408Z",
     "start_time": "2025-08-07T14:12:09.850057Z"
    },
    "id": "5c2c86b6"
   },
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "# for dirname, _, filenames in os.walk('.'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T14:12:10.802312Z",
     "start_time": "2025-08-07T14:12:10.743594Z"
    },
    "id": "949c5722697148bd"
   },
   "cell_type": "code",
   "source": [
    "!pip install pytorch_metric_learning\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
    "from pytorch_metric_learning.losses import SupConLoss\n",
    "\n",
    "# -----------------------------\n",
    "# Load and preprocess data\n",
    "# -----------------------------\n",
    "# Use Kaggle paths when running on Kaggle\n",
    "# MODEL_PATH = \"/kaggle/input/xlm-roberta-base-offline/xlm_roberta_base_offline\"\n",
    "# MODEL_PATH = \"C:/Users/satra/Downloads/xlm_roberta_base_offline\"\n",
    "MODEL_PATH = \"xlm-roberta-base\"\n",
    "\n",
    "\n",
    "# trn = \"/kaggle/input/jigsaw-agile-community-rules/train.csv\"\n",
    "# tst = \"/kaggle/input/jigsaw-agile-community-rules/test.csv\"\n",
    "trn = \"/content/drive/MyDrive/Colab Notebooks/train.csv\"\n",
    "tst = \"/content/drive/MyDrive/Colab Notebooks/test.csv\"\n",
    "df_trn = pd.read_csv(trn)\n",
    "# df_trn = df_trn.sample(frac=.05, random_state=42).reset_index(drop=True)\n",
    "\n",
    "df_tst = pd.read_csv(tst)\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    # Try to detect NVIDIA CUDA GPU first\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f\"Using NVIDIA CUDA GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.2f} GB\")\n",
    "        return device\n",
    "\n",
    "    # If no NVIDIA CUDA GPU, try to detect DirectML GPU\n",
    "    try:\n",
    "        if torch_directml.is_available():\n",
    "            device = torch_directml.device()\n",
    "            print(f\"Using DirectML GPU: {device}\")\n",
    "            # Add a small test to ensure it's truly usable\n",
    "            try:\n",
    "                _ = torch.tensor([1], device=device)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: DirectML device found but not usable ({e}). Falling back to CPU.\")\n",
    "                return torch.device(\"cpu\")\n",
    "            return device\n",
    "        else:\n",
    "            print(\"DirectML is NOT available.\")\n",
    "    except ImportError:\n",
    "        print(\"torch_directml not installed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking DirectML: {e}. Falling back to CPU.\")\n",
    "\n",
    "    # If neither GPU is found, fall back to CPU\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU (NVIDIA CUDA or DirectML) found. Using CPU.\")\n",
    "    return device\n",
    "\n",
    "\n",
    "def fill_empty_examples_pandas(df):\n",
    "    example_cols = ['positive_example_1', 'positive_example_2', 'negative_example_1', 'negative_example_2']\n",
    "    for col in example_cols:\n",
    "        df[col] = df[col].fillna('').astype(str)\n",
    "\n",
    "    df['positive_example_1'] = df['positive_example_1'].mask(df['positive_example_1'] == '', df['positive_example_2'])\n",
    "    df['positive_example_2'] = df['positive_example_2'].mask(df['positive_example_2'] == '', df['positive_example_1'])\n",
    "\n",
    "    df['negative_example_1'] = df['negative_example_1'].mask(df['negative_example_1'] == '', df['negative_example_2'])\n",
    "    df['negative_example_2'] = df['negative_example_2'].mask(df['negative_example_2'] == '', df['negative_example_1'])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_text(value):\n",
    "    return str(value) if pd.notna(value) else ''\n",
    "\n",
    "\n",
    "def extract_texts(row):\n",
    "    return {\n",
    "        \"body\": get_text(row[\"body\"]),\n",
    "        \"rule\": get_text(row[\"rule\"]),\n",
    "        \"subreddit\": get_text(row[\"subreddit\"]),\n",
    "        \"pos1\": f\"{get_text(row['positive_example_1'])}\",\n",
    "        \"pos2\": f\"{get_text(row['positive_example_2'])}\",\n",
    "        \"neg1\": f\"{get_text(row['negative_example_1'])}\",\n",
    "        \"neg2\": f\"{get_text(row['negative_example_2'])}\",\n",
    "    }\n",
    "\n",
    "df_trn = fill_empty_examples_pandas(df_trn)\n",
    "df_tst = fill_empty_examples_pandas(df_tst)\n",
    "\n",
    "df_trn[\"inputs\"] = df_trn.apply(extract_texts, axis=1)\n",
    "df_tst[\"inputs\"] = df_tst.apply(extract_texts, axis=1) # Apply to test data too\n",
    "\n",
    "N_EPOCHS = 8\n",
    "k_folds = 5\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset\n",
    "# -----------------------------\n",
    "class MultiInputDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=128, is_test=False): # Renamed df_trn to df for generality\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        item = {}\n",
    "        for field in [\"text_to_classify\", \"rule\", \"subreddit\"]:\n",
    "            encoded = self.tokenizer(\n",
    "                row[field],\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                max_length=self.max_len,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "\n",
    "            for key in encoded:\n",
    "                item[f\"{field}_{key}\"] = encoded[key].squeeze(0)\n",
    "        if not self.is_test:\n",
    "          item[\"label\"] = torch.tensor(row[\"rule_violation\"], dtype=torch.float32)\n",
    "        return item\n",
    "\n",
    "# -----------------------------\n",
    "# Model\n",
    "# -----------------------------\n",
    "class MultiInputBERT(nn.Module):\n",
    "    def __init__(self, model_name=MODEL_PATH, embedding_dim=256): # Added embedding_dim\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        # Projection head for contrastive learning\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(768 * 3, 512), # Input is concatenated CLS tokens\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, embedding_dim) # Output embedding for contrastive loss\n",
    "        )\n",
    "\n",
    "        # Original classifier for downstream task (can be re-attached or fine-tuned)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 1) # Classifier takes the projected embedding\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        cls_outputs = []\n",
    "        for field in [\"text_to_classify\", \"rule\", \"subreddit\"]:\n",
    "            out = self.bert(\n",
    "                input_ids=inputs[f\"{field}_input_ids\"],\n",
    "                attention_mask=inputs[f\"{field}_attention_mask\"]\n",
    "            )\n",
    "            cls_outputs.append(out.last_hidden_state[:, 0])  # CLS token\n",
    "\n",
    "        x = torch.cat(cls_outputs, dim=1)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Get embeddings from projection head\n",
    "        embeddings = self.projection_head(x)\n",
    "\n",
    "        # Get logits from classifier (for downstream task)\n",
    "        logits = self.classifier(embeddings)\n",
    "\n",
    "        return logits, embeddings # Return both\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Training and Evaluation\n",
    "# -----------------------------\n",
    "device = get_device()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "\n",
    "oof_preds = np.zeros(len(df_trn))\n",
    "test_preds_folds = [] # This is correct\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df_trn, df_trn[\"rule_violation\"])):\n",
    "    print(f\"----- Fold {fold+1} -----\")\n",
    "    train_df = df_trn.iloc[train_idx].reset_index(drop=True)\n",
    "    val_df = df_trn.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    # Use original training data without expansion\n",
    "    fold_train_df_for_model = train_df.copy()\n",
    "    fold_train_df_for_model['text_to_classify'] = fold_train_df_for_model['body']\n",
    "\n",
    "    # Prepare the VALIDATION data for this fold (using original body)\n",
    "    fold_val_df_for_model = val_df.copy()\n",
    "    fold_val_df_for_model['text_to_classify'] = fold_val_df_for_model['body']\n",
    "\n",
    "    train_dataset = MultiInputDataset(fold_train_df_for_model, tokenizer)\n",
    "    val_dataset = MultiInputDataset(fold_val_df_for_model, tokenizer)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "    # Prepare the TEST data for this fold (using original body)\n",
    "    fold_tst_df_for_model = df_tst.copy()\n",
    "    fold_tst_df_for_model['text_to_classify'] = fold_tst_df_for_model['body']\n",
    "    test_loader = DataLoader(MultiInputDataset(fold_tst_df_for_model, tokenizer, is_test=True), batch_size=8, shuffle=False)\n",
    "\n",
    "\n",
    "    model = MultiInputBERT().to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "    # Define the loss functions\n",
    "    contrastive_criterion = SupConLoss(temperature=0.07)\n",
    "    classification_criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    num_training_steps_per_fold = len(train_loader) * N_EPOCHS\n",
    "    num_warmup_steps_per_fold = int(num_training_steps_per_fold * 0.05)\n",
    "\n",
    "    # Initialize the scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=num_warmup_steps_per_fold,\n",
    "        num_training_steps=num_training_steps_per_fold\n",
    "    )\n",
    "\n",
    "    # Training Loop for this fold\n",
    "    best_auc = -1.0 # Track best AUC for this fold\n",
    "    best_model_state = None # To save the best model for this fold\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n",
    "            inputs = {k: v.to(device) for k, v in batch.items() if k != \"label\"}\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Get both logits and embeddings\n",
    "            logits, embeddings = model(inputs)\n",
    "\n",
    "            # --- Combined Loss ---\n",
    "            # 1. Contrastive Loss\n",
    "            loss_supcon = contrastive_criterion(embeddings, labels)\n",
    "\n",
    "            # 2. Classification Loss\n",
    "            loss_bce = classification_criterion(logits.squeeze(-1), labels)\n",
    "\n",
    "            # Combine the two losses. You can experiment with weighting them, e.g., loss = 0.5 * loss_supcon + 0.5 * loss_bce\n",
    "            loss = loss_supcon + loss_bce\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1} Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "        # Eval (for monitoring, still using AUC on classification task)\n",
    "        model.eval()\n",
    "        preds_raw, labels_all = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=f\"Validating Epoch {epoch+1}\"):\n",
    "                inputs = {k: v.to(device) for k, v in batch.items() if k != \"label\"}\n",
    "                labels = batch[\"label\"].to(device)\n",
    "\n",
    "                # Get logits for evaluation\n",
    "                logits, _ = model(inputs)\n",
    "                logits = logits.squeeze(-1) # Squeeze to [batch_size]\n",
    "\n",
    "                probs = torch.sigmoid(logits).detach().cpu().tolist()\n",
    "                preds_raw.extend(probs)\n",
    "                labels_all.extend(labels.cpu().tolist())\n",
    "\n",
    "            # Hard labels (for classification report, optional)\n",
    "            preds = [int(p > 0.5) for p in preds_raw]\n",
    "\n",
    "            # Print metrics\n",
    "            print(classification_report(labels_all, preds, digits=3, zero_division=0))\n",
    "\n",
    "            curr_auc = roc_auc_score(labels_all, preds_raw)\n",
    "            print(f\"AUC Score: {curr_auc:.4f}\")\n",
    "\n",
    "            # Add sanity check for labels\n",
    "            print(f\"Sample of labels in validation batch: {labels.cpu().numpy()[:5]}\")\n",
    "\n",
    "            # Save the best model for this fold based on validation AUC\n",
    "            if curr_auc > best_auc:\n",
    "                best_auc = curr_auc\n",
    "                best_model_state = model.state_dict() # Save model weights\n",
    "                print(f\"  -> New best Val AUC for Fold {fold+1}: {best_auc:.4f}\")\n",
    "\n",
    "    # 6. Load best model state for this fold\n",
    "    model.load_state_dict(best_model_state) # Use best_model_state\n",
    "    print(f\"Fold {fold+1} Best Val AUC: {best_auc:.4f}\")\n",
    "\n",
    "    # Make OOF predictions for this fold's validation set\n",
    "    model.eval()\n",
    "    fold_val_preds_list = []\n",
    "    fold_val_true_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f\"Fold {fold+1} OOF Prediction\"):\n",
    "            inputs = {k: v.to(device) for k, v in batch.items() if k != \"label\"}\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            logits, _ = model(inputs)\n",
    "            logits = logits.squeeze(-1) # Squeeze to [batch_size]\n",
    "            probs = torch.sigmoid(logits).detach().cpu().tolist()\n",
    "            fold_val_preds_list.extend(probs)\n",
    "            fold_val_true_list.extend(labels.cpu().tolist())\n",
    "\n",
    "    oof_fold_auc_check = roc_auc_score(fold_val_true_list, fold_val_preds_list)\n",
    "    print(f\"Fold {fold+1} OOF AUC Check: {oof_fold_auc_check:.4f} (Must match Best Val AUC)\")\n",
    "\n",
    "    oof_preds[val_idx] = np.array(fold_val_preds_list) # Use val_idx from kf.split\n",
    "\n",
    "    # Make predictions on the TEST set using this fold's best model\n",
    "    test_fold_preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=f\"Fold {fold+1} Test Prediction\"):\n",
    "            inputs = {k: v.to(device) for k, v in batch.items()}\n",
    "            logits, _ = model(inputs)\n",
    "            logits = logits.squeeze(-1) # Squeeze to [batch_size]\n",
    "            probs = torch.sigmoid(logits).detach().cpu().tolist()\n",
    "            test_fold_preds.extend(probs)\n",
    "\n",
    "    test_preds_folds.append(test_fold_preds) # Store test predictions from this fold\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Final Calculation and Submission\n",
    "# -----------------------------\n",
    "overall_oof_auc = roc_auc_score(df_trn['rule_violation'], oof_preds)\n",
    "print(f\"Overall {k_folds}-Fold OOF AUC: {overall_oof_auc:.4f} ---\")\n",
    "\n",
    "# Average test predictions across all folds\n",
    "final_test_predictions = np.mean(test_preds_folds, axis=0)\n",
    "\n",
    "# Create final submission file\n",
    "submission = pd.DataFrame({\n",
    "    \"row_id\": df_tst[\"row_id\"],\n",
    "    \"rule_violation\": final_test_predictions\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False) # Save with a distinct name\n",
    "print(\"K-Fold multi-input submission.csv created successfully!\")\n",
    "print(submission.head(10))\n"
   ],
   "id": "949c5722697148bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "HJiik1MiRHr4"
   },
   "id": "HJiik1MiRHr4",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 13121456,
     "isSourceIdPinned": false,
     "sourceId": 94635,
     "sourceType": "competition"
    },
    {
     "datasetId": 7984956,
     "sourceId": 12636496,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7311.633087,
   "end_time": "2025-08-03T16:13:47.493920",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-03T14:11:55.860833",
   "version": "2.6.0"
  },
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "L4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
